[{"categories":null,"contents":"","date":"Nov 26","permalink":"http://blog.ibyte.me/projects/fw_project/","tags":null,"title":"falsework"},{"categories":null,"contents":"","date":"Nov 26","permalink":"http://blog.ibyte.me/projects/gsql_project/","tags":null,"title":"gsql"},{"categories":null,"contents":"","date":"Nov 26","permalink":"http://blog.ibyte.me/projects/s2s_project/","tags":null,"title":"s2s"},{"categories":null,"contents":"","date":"Nov 26","permalink":"http://blog.ibyte.me/projects/sessionx_project/","tags":null,"title":"sessionx"},{"categories":null,"contents":"   文件系统  现在计算机数据存储功能是必不可少的，大家的图片和视频都是数据，但是这些数据是怎么保存在硬盘上的呢？我不知道大家有没有想过？存储介质分类有很多种，例如：机械硬盘、固态硬盘、闪存\u0026hellip;这些都是物理存储介质，怎么让数据保存在里面？不丢失？那么多数据又是怎么在组织起来管理的呢？这时就要说说文件系统了。\n文件系统就是操作系统给我们抽象一种中间层让我们和物理磁盘可以打交道，文件系统就是负责把用户的文件存到磁盘硬件中，因为即使计算机断电了，磁盘里的数据并不会丢失，所以可以持久化的保存文件。\n   怎么工作的？  文件系统怎么工作的？无论底层存储介质是磁盘还是SSD，都被该层抽象为 Block 的概念。文件系统在初始化时，会先在挂载的块存储上的第一个位置创建一个 Super Block，文件在抽象之前，每个文件是有元数据信息的，例如：文件名字、文件大小、创建时间、访问时间、归属者、所在组等\u0026hellip;构成元数据信息，好比现实中一本书，书的各种信息。\nLinux 最经典的一句话是：一切皆文件!，不仅普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的，但是这些信息要怎么组织到磁盘上，而且文件可能随着时间推移大小也随着变化，文件可能被拷贝到不同物理介质上，这就给文件系统设计者带来一个大问题？\n文件系统会把底层存储的物理硬盘设备，抽象成单单固定大小的块，块区，那这么多快和分区要怎么组织去管理？后面出现了一种基于inode 索引节点的文件组织管理方式。\n   文件组织管理方式  硬件磁盘会被划分成固定大小块，存储块大小可能是512字节的sector然后8个组成一个4KB的块，这个看具体划分方式了，文件也是对应的这么划分存储的，这么设计的时候那就可以把每个块加上唯一编号，也可以看成文件的名字，然后把块建立一个索引，但是大部分存储文件的都是以mb作为单位的，例如：一部电影可能有4GB大小，这就给快存储设计带来设计挑战，一个4GB的电影就需要100万个4kb的块，但是每个块上还有一个唯一的文件名称或者编号，需要占用8字节的空间，这么一搞那么就需要另外的8mb记录，又带了来这样的问题？\n有了这些问题，文件系统设计者引入一个叫index node的数据结构，文件数据被存储不同块里面，文件的元数据信息就会被存储在inode里面。\ninode会被存储在inode table里面的，inode也就是inode table里面条目，inode table 包含该文件系统中所有文件的列表，inode table 中的各个 inode 项具有唯一的编号。\ninode table记录这个inode number对应文件所对应的metadata，如上图所示👆🏻，这样我们就方便管理文件元数据了，每个 inode 都有一个号码，操作系统用 inode 号码来识别不同的文件，这里值得重复一遍，Unix/Linux 系统内部不使用文件名，而使用 inode 号码来识别文件。对于系统来说，文件名只是 inode 号码便于识别的别称一样。\n我们在系统调用的时候，发生了什么？实际上，系统内部将这个过程分成三步：\n 系统找到文件名对应的 inode number 通过 inode number，获取 inode 信息 根据 inode 信息，找到文件数据所在的 block，读写数据。     inode 怎么工作的？  通过上面的了解，得知了每个文件都对应一个inode，然后管理文件的时候把所有文件块存储在inode里面但是这种不是没有问题的，随着时间文件不断加大，inode就要在创建的时候就预留足够好的空间，才能保证后面文件的各种变化，例如我未来存储文件是4GB，我现在就要去把inode占用大小设置为8mb显然这个不能充分发挥磁盘利用率。如果inode分配小了，未来文件变大了，inode不够用，各种问题。。。\nLinux系统为了解决这个问题，引入和虚拟内存的那种概念，把inode通过采用分级的方式来组织存储块号，inode为了解决数据变化问题，它引入了3个存储指针设计。\ninode中保存了3种指针，inode有12个直接指针，间接指针有3，二级指针就1个，可以存储设备的块号，第一个指针为直接指针可以直接指向数据块本身，数据块就是保存数据的块，第二针指针是间接指针，间接指针是在前面的指针指针不够的时候才会启用，间接指针可以看成链表那样，间接指针会指向一个一个级索引块，这块本身又是一个数据块的指针也是只是指向存储数据块，第3类指针，指向一个二级索引块，二级索引块的指针还可以指向新的索引块，这样一来就可以动态划分INODE了。\n   小结  很多看完说这个有什么用？如果不做系统底层的开发的话，如果你这么想，我只是觉得你很肤浅！😒，看完inode的设计马上就可以联想到一个分布式文件系统雏形，有时候要懂得变通的。例如Google 的GFS系统，当然据我所知gfs已经没有使用了，取代gfs是一个款新的叫Colossus系统，这个系统目前设计细节没有公开，但是我看到有cmu的朋友说Google Infra Team的Larry Greenfield的一个Lecture其中介绍了Larry对GFS的设计初衷理念、优劣势、瓶颈、改进，然后研发了现役系统Colossus (GFS2)系统，当然操作系统的文件系统设计细节远远不止本文所讲的inode，但是inode对组织管理文件起到了很大作用，希望读读者有帮助吧，我也是个人笔记分享。\n","date":"Dec 26","permalink":"http://blog.ibyte.me/post/linux-file-system-inode/","tags":null,"title":"Linux File System Inode"},{"categories":null,"contents":"   为什么有这篇文章  某一天在群里摸鱼的时候，看到群里有人问go map的空间回收问题，把截图贴上吧： 其实一位群友发出的问题引起了我注意，他的问题是：go的map的值调用了delete函数是不是不会立即删除？当然这个问题如果研究过或者深入go的内存分配或者说有了解过go的gc应该知道，这个问题答案。\n关于是分段锁的应用和怎么去优化gc带来的影响，有一个开源项目bigcache在这方面做的比较好。\n   BigCache的设计   官方作者介绍：快速，并发，基于内存的缓存库，由于是嵌入式库也省去了网络上的开销，完全基于本地内存，能保存大量数据项的同时并且对go语言的garbage collection进行了优化。\n 对并发锁的颗粒度减小，并且对gc优化它怎么做的？\n 分段锁 数据二进制存储，避免让gc去嵌套扫描 加速并发访问 避免高额的GC开销  官方在他们blog上列出了，他们当时写这个库的需求：\n 处理10k rps (写5000，读5000) cache对象至少存活10分钟 更快的响应时间 POST请求的每条 JSON 消息,一有含有ID，二不大于500字节 POST请求添加缓存后，GET能获取到最新结果  Go map 的问题\n我在网上看到资料有提到一个问题：https://github.com/golang/go/issues/9477\n大致看了一下这个说了问题就是，Go 1.3和1.4RC1垃圾回收在扫描一个大的map时需要50-70ms时间，问官方怎么能有什么办法减小这个时间。\n然后1.5版本，如果 map 的 key 或 value 中都不含指针， GC 便会忽略这个 map。\n主要的也就两个结构体cache和cacheShard:\n1 2 3 4  type cache struct { shards []*cacheShard // 块map 解决并发锁颗粒度问题  hash fnv64a // 哈希函数 }   源码中的哈希函数用的是fnv64a算法，这个算法的好处是采用位运算的方式在栈上进行运算，避免在堆上分配。\nshards用来保存cacheShard的，而cacheShard也就是具体存储数据的缓存块，hash会对输入的key进行计算得到cacheShard坐标拿到具体的cacheShard，每个cacheShard都有自己的锁所以才能保证小锁颗粒度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  type cacheShard struct { hashmap map[uint64]uint32\t// 外部索引  entries queue.BytesQueue // 存储序列化也就是byte形式存储的数据  lock sync.RWMutex // 单个锁  entryBuffer []byte onRemove onRemoveCallback // 移除回调函数  isVerbose bool statsEnabled bool logger Logger clock clock lifeWindow uint64 hashmapStats map[uint64]uint32 stats Stats }   cacheShard 中的hashmap结构的类型map[uint64]uint32，完全和key使用的string 扯不上关系，有经验的老司机一眼就看出这其实是个索引，uint64存储的外部键的哈希值，而后面的uint32用处是存储值的位置，而真正的数据存储在BytesQueue中，通过外部索引的值uint32类型来获取里面的值所在的位置索引，而BytesQueue又是经过二进制序列化的数据，取的时候提供外部索引得到坐标取值，最为妙处的设计就是外部索引不存储指针，也不存储符合结构，使得 garbage collection的影响降到最小。\nBytesQueue结构体中的array是存储主要数据的byte数组，capacity是使用容量，maxCapacity在创建的时候可以指定最大容量，tail类似链表里面的尾指针，下次插入值可以通过这个指针找到插入的位置，count当前存储的数据条目数，headerBuffer是起到了一个切片发送拷贝时充当零时缓冲区的作用。\n有兴趣自己去看源代码吧：https://github.com/allegro/bigcache\n   总结  BigCache的设计真的很妙，当然这个妙首先你得了解go的gc一些工作方式，然后针对这个这些特定，去优化数据结构，BigCache为了减小锁的颗粒度使用了分段分片，然后防止gc对数据进行扫描的耗时，有把数据采用无指针嵌套的二进制方式去存储，能避免gc去针对底层的数据进行引用存活相关的检测耗时，唯一缺点就是BigCache数据不能持久化存储。\n","date":"Dec 24","permalink":"http://blog.ibyte.me/post/bigcache-golang-garbage-collection/","tags":null,"title":"Bigcache Golang Garbage Collection"},{"categories":null,"contents":"   天上飞的概念，也要落地的实现  Bitcask相信如果你了解或者做过存储相关的工作的，相信或多或少都了解过，它是由basho的bitcask论文所设计的key-value存储引擎，相关的应用有Riak这个数据库，Riak是以 Erlang 开发的一个高度可扩展的分布式数据存储，Riak的实现是基于Amazon的Dynamo论文实现的，说到Dynomo那是另外一篇论文的事情了（如果你想看中文版我上一篇文章就是翻译的Dynamo论文可以找找历史记录），Dynamo他们也根据自己的实际应用做了相应的优化，言归正传，这篇我还是围绕Bitcask存储引擎在KVBase落地的实现写写。\n   Bitcask怎么工作的？  Bitcask是使用RAM 存储指向值的文件指针的哈希映射，索引用于高效写入的日志结构文件系统，二者组合而成的存储引擎，可能光文章描述可能很难理解，我下面画了几幅图。\nBitcask主要几个组件，我个人认为最重要也就3个组件：\n Index Map 全局索引映射 Active File 当前可写文件的指针 Compressor 负责脏数据压缩和整理进程  key会存储在内存中以便快速查找，所有的value都存储于磁盘中，这种方法特点是以追加的方式写磁盘，即写操作是有序的，这样可以减少磁磁盘的寻道时间，是一种高吞吐量的写入方案，在更新数据时，也是把新数据追加到文件的后面，然后更新一下数据的文件指针映射即可。\n当写操作发生时，keydir被原子的更新，更新成新的文件上的位置，文件上的老数据还在磁盘上，新的读操作会使用新的keydir，如果在并发大量请求情况下，这个估计会出现性能瓶颈的地方之一，这个坑我会在后面说说怎么去优化。\nActive File是在磁盘上的文件，每条数据对应数据格式如下图：\n每条数据都一条一条以行的形式存储在数据文件里，如图上通过特殊的编码方式就可以得到key的大小和value的大小，然后就可以找到key的位置和value的内容然后反编码解码操作，数据在写入的时候是被编码成二进制的存储的，补充一下CRC是循环校验码，是数据通信领域中最常用的一种差错校验码，毕竟数据库里面的数据有时候需要在网络上进行传输。\n   Bitcask缺陷   这种基于内存的索引的必然有问题的，例如机器重启，内存数据丢了，索引就无法对磁盘数进行映射，还有上面提到的全局的读写必须经过这个keydir进行定位到数据源，另外读取数据的依赖于操作系统内核的文件系统缓存，没有用户态实现，不可控。\n  为了解决重启内存索引数据丢失的问题，Bitcask论文中提到了hint file文件，如果是直接扫描data文件然后来建立索引是一件非常耗时的工作，要调用操作系统打开多个数据文件，然后来回遍历记录，官方解决方案是在一部分data文件记录对应一个hint文件，扫描一个hint file相比去读取data文件要省事的多，里面记录如下：  第二个问题就是数据都是增删改查的，数据被删除是肯定会发生的，那么Bitcask作为一个只追加记录的引擎，怎么解决？随着记录不断增多，数据文件也会变得更大，为了节省空间，bitcask采用merge的方式剔除脏数据，merge期间会影响到服务的访问，如果想保留原始的数据文件，可以使用谷歌的Snappy压缩算法，在磁盘IO和cpu之间做一个权衡，以便使程序跑得更快，Snappy就是这样一种快速的数据压缩算法。对于一个核的i7处理器（64位模式），能达到250M/s以上的处理速度。  针对这个问题，我对KVBase采用的bit桶key标记删除策略，当被删除的key达到一定数量的时候（通过算法去判定是否需要），如果需要就会启动一个独立进程去访问为未被标记的数据，并且开始整理到新的数据文件中，在此期间服务依然可用，整理完成之后我只需要原子操作把内存映射的指针指向新的索引上，这个过程比bitcask论文用的整个合并数据文件要好得多，不会因为整理过程中整个服务被阻塞着，最多就是短暂消耗一点内存空间罢了，整理完成之后清理废弃内存数据和内存空间，这也是牺牲空间换取可用性和时间。我承认这个设计借鉴了Golang原生的map的扩容策略，如果你对go原生的map有了解的话，或者是看过go源代码的话，应该很清楚。\n   KVBase的设计  要知道Bitcask是以追加的方式写磁盘，即写操作是有序的，这样可以减少磁磁盘的寻道时间，是一种高吞吐量的写入设计，写性能肯定是没有得话说的。但是读取数据是通过内存中索引进行查询读取，虽然key的定位是通过hash进行O(1)时间复杂度，但是如果数据存放在老数据文件里面，此时就要调用系统内核api去读取文件，会产生短暂的io开销。\n为了解决读取性能的问题，我在KVBase上加了层cache并且这层cache是支持分布式的，为什么这么做？要知道数据存储问题底层的Bitcask引擎已经解决了，写入数据不就是为了数据不能丢吗？这个问题已经解决了，大部分写数据场景估计也不多，大部分都是读数据场景，所以加一层基于内存的cache为读取数据，提供保障，为了解决内存空间大小没有磁盘空间大的问题，引入一些内存淘汰算法，保证空间问题，当然具体哪个我还在考量，或者像redis那样从内存数据里面随机抽取一部分数据，如果超过4/1的数据即将过期，那么就重复抽样几次：\n底层存储已经和cache被单独抽象出来了，以后就算换掉底层的存储引擎实现也不会影响上层cache，在KVBase我个人认为存储引擎只是为cache服务的，cache被抽象成了分布式的了，意味着后面我可以动态分配数据存储节点，这个就没有什么好讲的了。\n   小结  如果这篇文章对读者有什么启发，那我很高兴，文章也是一种技术分享，如果你对这块感兴趣，有什么想吐槽的，我非常欢迎交流，实质来一起coding。\n","date":"Dec 21","permalink":"http://blog.ibyte.me/post/bitcask-kvbase/","tags":null,"title":"KVBase storage engine Bitcask"},{"categories":null,"contents":"   为什么会出现集群架构？  上一篇写到了redis哨兵模式，这种模式虽然能解决一些并发情况下的数据请求压力问题和可用性问题，主从替换以及故障恢复。哨兵模式只是redis架构在历史演变过程中一个的转折点，哨兵这种模式主从模式的数据都是全量同步的，也就是每个从节点上的数据都是主节点上的数据副本，大家想一想有木有问题？\n是不是太浪费内存了？或者说可不可以把全量的数据拆解成部分数据，然后分布在不同节点上？那么这种有什么好处吗？？？\n如果数据全部存储在一台机子上，全量同步的时候会时间过长，有时候出现了big key情况更是一个问题，网络一波动，本来传输正在进行中，一半断掉了，会增加同步失败的概率。分片的存储好处，是不是可以减低这些风险的，每个节点我存储一部分数据，实质我们可以交叉存储数据块，a节点存储b节点一个副本，b节点存储a节点一个副本，这样就算如果a当掉了，我们是不是可以去b里面拿取副本继续使用，当然这个我是自己的一些看法，我看hdfs就是这么设计的，当然redis没有这个交叉存储策略，但是笔者认为如果在key下功夫也可以达到的，把key以特定格式的命名的格式二次存储也能达到，只是说浪费一点内存吧了。\n   存储模型  有木有想过为什么redis为什么是k:v这种存储模型，而不是直接设计成关系型数据库那样的？？熟悉redis应该都了解一点历史，使用key-value是有历史原因的，早期的时候，redis作者起初是为提高自己网站的读写并发能力而创建redis，而key-value字典结构的常规时间复杂度是O(1)，刚好满足作者的性能要求和业务数据结构需求。\nredis大部分作用都是缓存数据的，大部分数据都是从db读取的，而且这些数据也不是db中全量的数据，只是一部分而已，没有高度组织化结构化数据，用一部分数据，怎么组成一个完整的关系模型？所以不需要结构化查询语言。\n   Codis分片方案  正是redis作者这些历史原因，本来在设计之初可能也就是单机就可以满足作者自己的需求，但是没想到它写的这个软件被这么多人使用，影响力这么大，然后出现了主从模式，哨兵模式，直到本文要讲的集群模式。\n 计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决!\n Redis的集群也有演变历史，早期有Twemproxy是Twitter团队的开源的解决分片方案，还有Codis的方案值得注意这是一个国人开源的，也就是现在pingcap几位创始人，前豌豆荚团队的，不得不说屌爆了。\n他们方案都有一个共同特点，都是通过一个proxy代理层进行的分片处理的，不知道有没有使用过Nginx的，使用过大家应该知道Nginx反向代理一些服务程序，例如Nginx和Tomcat组成一个反向代理负载均衡的集群，codis也是类似这样的方案。\nCodis就是起着一个中间代理的作用，Codis内部维护一个key映射算法，客户端访问codis和直接访问redis没有区别的，因为codis实现了redis的通讯协议，协议这个东西很重要的，双方都商量好的怎么处理数据，做起事来，就很方便，大家懂得。。。。Codis是一个无状态的，所以可以增加多个Codis来提升QPS,同时也可以起着扩容的作用。\nCodis怎么工作的？\n  在Codis会把所有的key分成1024个槽，这1024个槽对应着的就是Redis的集群，这个在Codis中是会在内存中维护着这1024个槽与Redis实例的映射的，当然这个是可以配置，就看你的Redis的节点数量有多少，偏多的话，可以设置槽多一些。\n  codis会先是把key进行CRC32 后，得到一个32位的数字，然后再hash%1024后得到一个余数，这个值就是这个key对应着的槽，这槽后面对应着的就是redis的实例。\n  那么问题来了？我多个codis怎么解决槽位共享？\nCodis把这个工作交给了ZooKeeper来管理，Codis节点会监听到ZooKeeper的槽位变化，会及时同步过来，如下图\n这种方式有木有什么弊端？？？\n如果是使用mset批量设置值，值是是不是被分散在各个节点上，还有如果rename的时候也是一个问题，不过我认为有一种解决方案在映射的时候给key生成一个唯一的uuid，我rename的只是key，而映射的时候使用uuid计算槽位，当然这些问题在后面的redis官方解决方案里面得到了解决。\n   官方集群方案  说起官方集群解决方案，是redis作者在前面那些代理中间件出现之后发布的，我看他这个设计之后感觉应该借鉴了codis的设计方案，只是把集群槽位信息同步改成p2p然后通过gossip协议来解决了同步的问题，个人感觉都是都是redis在设计之初留下技术负债问题，早期的时候估计作者自己也没有打算写集群方案，被逼的，当然这个是我个人的想法和看法。\n相对于 Codis 的不同，它是去中心化的，如图下面我画的图，该集群有4个 Redis 节点组成， 每个节点负责整个集群的一部分数据，每个节点负责的数据多少可能不一样，这4个节点相 互连接组成一个对等的集群，它们之间通过一种gossip协议相互交互集群信息。\n当然我上面画的图太接近一致性哈希环了，但是设计思想是接近的，Redis Cluster 将所有数据划分为 16384 的 slots，比 Codis 的 1024 个槽划分得更为精细，每个节点负责其中一部分槽，槽位的信息存储于每个节点中，它不像 Codis存储在zookeeper中，相信大家都听说过p2p，不清楚自己去查吧。。\n那么问题来了！客户端怎么获取不同节点中的key呢？\n有木有想过，我客户端连接的是a节点，而我要的数据在b节点上，这个问题怎么解决的呢？redis在通讯协议上下了功夫！它借鉴了http协议的重定向的概念，大家的应该熟悉http中重定向协议吧，如下图：\n客户端来连接集群时，它也会得到一份集群的槽位配置信息。这样当客户端要查找某个 key 时，可以直接定位到目标节点，这么一来就解决了数据重定向拿取问题，上面我说到了codis的rename问题，官方解决方案是可以让客户端把每个key设置一个tag然后指定到对应节点槽位上，想深入了解的自己看看一些资料吧，我这里主要讲大问题思路。\n这种模式就十全十美了吗？没有其他问题了吗？\n从上面我画的图就能看出来，集群内置了16384个slot，并且把所有的物理节点映射到了这16384个slot上，或者说把这些slot均等的分配给了各个节点，但是这种分片模式，肯定是有问题的，例如一个节点挂掉了，那么整个集群中的一部分数据丢失了，数据就不是完整的了，有什么办法解决？\n解决办法还是有的每个分片节点备几个从节点，从主节点上读取数据到从节点上，和哨兵模式一样，有问题自己从节点顶上。\n   小结  redis集群采用P2P模式，是完全去中心化的，不存在中心节点或者代理节点，都是历史遇到问题就出解决方案演进过来的。估计作者早期也就是打算设计的时候一个单机就能解决问题了，没想到，万万没想到啊，用的人那么多，然后出现分布式问题哈哈哈哈。。所以出现了各种解决方案，不管什么解决方案，redis数据不能做到保证强一致性，一些已经向客户端确认写成功的操作，会在某些不确定的情况下丢失，而且由于集群方案都是把一大块数据使用分治法打散在各个节点上，支持acid更是一个问题，这估计也是在历史设计的时候留下的问题，但是大部分场景redis都是做缓存服务器用用可以了。\n好了本文是redis系统设计系列最后一章了，后面再找找其他NB的系统设计写写，好看不过瘾，那你倒是点个关注啊。。。。\n   文末立个flag  KVBase要开始动工了，先把flag立在这儿，logo都设计好了，管它三七二十一把第一个版本撸出来再说，然后慢慢迭代。\n","date":"Nov 24","permalink":"http://blog.ibyte.me/post/redis-cluster-system-desgin/","tags":null,"title":"Redis Cluster System Desgin"},{"categories":null,"contents":"   CAP理论  CAP理论是什么？ 可以这么说吧cap理论是分布式系统的奠基石吧，这个理论论述分布式系统设计的3个最大问题：\n 一致性 (Consistency) 可用性 (Availability) 分区容错性 (Partition Tolerance)  什么是一致性？假设一个集群有2个节点A-1和A-2，这两个节点为主从关系，例如redis里面的主从模式。主节点负责写入数据，从节点负责从主节点同步数据到本机。\nA-1和A-2 通过网络进行数据同步，要怎么保证两台机子上的数据一致的呢？这个就是数据一致性问题。\n那什么是可用性？A-1和A-2两台机子做成一个集群，实际上真实情况可能更多，在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求，例如A-1挂掉以后，A-2会马上接管这些请求的，保持整体可用性。\n那什么是分区容错性？一个集群都靠着网络进行通讯的，如果网络波动，这个集群中的部分节点网络和集群上的其他节点联通不了，那么数据一致性就很难保持了，网络一断开，那么那么整个集群可能被划分成多个独立的小分区了，如果在短时间内不能联通同步数据，这就是出现网络分区问题。\n如上图 A-1和A-3网络连接出现了故障，那么这个集群就已经存在了网络分区问题！但是整体集群而看上去却好像是在一个可以运转正常，其他剩下的机器还能够正常运转满足系统需求，对于用户而言并没有什么体验上的影响。\n所以在设计分布式系统时，CAP问题必会出现！除非你玩单机系统😜！怎么优雅解决问题，就看设计者了在A和C、P之前怎么做决策了。用这些问题我去套用在redis集群模式上，看redis集群是怎么解决CAP问题的。\n   Redis哨兵  Redis早期版本，redis单机情况下即便性能强的一批，但是大规模数据或者海量请求下还是为支撑不了可用性和稳定性，后面redis官方有一个解决方案就是哨兵模式。\n哨兵模式：上面提到了主从架构，主从切换技术方案是，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这中间就需要人工干预，例如大半夜收到报警，爬起来手动切换服务器？？？需要手动将 从节点 晋升为 主节点，同时还要通知 客户端 更新 主节点地址，显然这种问题怎么可能忍？大家都是程序员自己写个程序自动化不就好了，为什么要用这么笨方式。。。哨兵模式哨兵就是解决这个问题的，哨兵是一个独立的进程，作为进程，它会独立运行，其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例，当有一个节点挂掉的时候，客户端连接其节点失败，就会向哨兵服务器询问新的节点地址然后继续使用，其他从节点也会跟着把主节点调整到新节点上，哨兵还会记录当前挂掉节点状态，还会定时进行查看如果复活了还会添加到哨兵集群里，从而达到无人干扰。\n   增量同步\u0026amp;amp;全量同步  上面哨兵模式切换过程，提到了主从，那主从节点数据，怎么保证一致性的的？在redis集群情况下同步模式有两种：\n 增量同步 全量同步  设想一下主从节点在某个网络情况出现问题波动，这是客户端正在朝着服务器端主节点，写数据，而从节点又在从主节点读取同步被写入的数据，这时网络一波动，那么就出现网络分区了。出现网络分区了，此时两个节点就处于独立的单机状态，如图：\n正如上图所话的，主从在短时间内出现网络分区，redis的设计者针对这个方案提出了一个方案叫增量复制，如下图，当然这个图我之前讲go中的channel的时候画的，反正是同用的，所以懒得话了，直接拿过来用一用。\nredis在每个主节点上分配一快ring也可以叫为buf，这个ring是里面就记录它自身大小元素个数的最近客户端执行命令记录，如果从节点短时间内恢复了链接，此时从节点直接去主节点的ring中拿取命令记录数据，然后在自己本机上跑一遍。\n增量复制不是没有问题的，设想一下如果这个网络分区出现很长时间，这个ring容量是不是不够用，所有第二套解决方案出现了，全量同步这个过程是怎么样的？\n直接把redis在内存里面的数据通过序列化然后通过网络发送到从节点，从节点在本地保存，然后全量加载到内存里面完成数据恢复，在全量同步的时候，可能也有其他命令漏掉，还会配上增量复制进行。\n   小结  目前只说到Redis哨兵模式了，这个模式能解决一部分CAP问题，例如还有：节点动态添加，数据动态迁移。。。这些问题在下一篇文章写，也是经典的分而治之的应用。\n","date":"Nov 10","permalink":"http://blog.ibyte.me/post/how-redis-solves-the-cap-problem/","tags":null,"title":"How Redis Solves the CAP Problem"},{"categories":null,"contents":"   Redis的高性能怎么做到的？  Redis这个NOSQL数据库在计算机界可谓是无人不知，无人不晓。只要涉及到数据那么就需要数据库，数据库类型很多，但是NOSQL的kv内存数据库也很多，redis作为其中一个是怎么做到行业天花板的呢？是怎么做到高性能的呢？怎么做到高可用的呢？今天这篇八股文我就整理一些redis的设计写写，本篇还是偏关于高性能这一块。\n   高效数据结构  Redis的数据库相比传统的关系数据库，在数据结构上也是比较特殊的，它的所有数据类型都可以看做是一个map的结构，key作为查询条件。\nRedis基于KV内存数据库，它内部构建了一个哈希表，根据指定的KEY访问时，只需要O(1)的时间复杂度就可以找到对应的数据，而value的值又是一些拥有各种特性的数据结构，这就给redis在数据操作的时候提供很好的性能了。\n   基于内存存储  相比传统的关系数据库，数据文件可能以lsm tree 或者 b+ tree形式存在硬盘上，这个时候读取文件要有io操作了，而redis在内存中进行，并不会大量消耗CPU资源，所以速度极快。\n内存从上图可以看到它介于硬盘和cpu缓存中间的，相比硬盘查找数据肯定是快的，当然这里笔者个人见解上，如果关系型数据库把一些平凡操作的数据库也放置在内存中缓存，也会得到一些性能的提升，像操作系统里面缺页异常一样处理，把数据片段通过一些特殊算法缓存在内存里面，减少文件io的开销。\n   io多路复用  传统对于并发情况，假如一个进程不行，那搞多个进程不就可以同时处理多个客户端连接了么？多进程是可以解决一些并发问题，但是还是有一些问题，上下文切换开销，线程循环创建，从PCB来回恢复效率较低。随着客户端请求增多，那么线程也随着请求数量直线上升，如果是并发的时候涉及到数据共享访问，有时候涉及到使用锁来控制范围顺序，影响其他线程执行效率。（进程在Linux也可以理解为线程，每个进程只是有一个线程，当然这里我上面写的进程，别纠结这些。。。）\n线程是运行在进程上下文的逻辑流，一个进程可以包含多个线程，多个线程运行在同一进程上下文中，因此可共享这个进程地址空间的所有内容，解决了进程与进程之间通信难的问题，同时，由于一个线程的上下文要比一个进程的上下文小得多，所以线程的上下文切换，要比进程的上下文切换效率高得多。\n像redis和Nginx这种应用就是单线程的程序，为什么他们能做到这么强的性能？首先看一个例子：\n Blocking IO   中午吃饭，我给餐厅老板说要一碗‘热干面’，然后我就在那边一直等着老板做，老板没有做好，我就一直在哪里等着什么也不做，直到‘热干面’做好。\n 这个流程就是我们常说的Blocking I/O如图：\n同步阻塞 IO 模型中，应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。\n Non Blocking IO  切换一下常见：\n 同样你中午吃饭，给餐厅老板说要一碗‘热干面’，然后老板开始做了，你每隔几分钟向老板问一下‘好了吗？’，直到老板说好了，你取到‘热干面’结束。\n 同步非阻塞 IO 模型中，应用程序会一直发起read调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间，通过轮询操作，避免了一直阻塞，取回热干面的过程就是内核把准备好的数据交换到用户空间过程。\n综上两种模型，缺点都是差不多，都是在等待内核准备数据，然后阻塞等待，同样逃不开阻塞这个问题，应用程序不断进行I/O系统调用轮询数据是否已经准备好的过程是十分消耗CPU资源的。\nI/O Multiplexing  还是之前那个例子：\n 中午吃饭，给餐厅老板说要一碗‘热干面’，然后老板安排给下面的厨子做，具体哪个厨子做不知道，有好几个厨子，然后老板每隔一段时间询问下面的厨子有木有做好，如果做好了，就通知我来去取餐。\n IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用，read 调用的过程（数据从内核空间-\u0026gt;用户空间）还是阻塞的。\nReactor 通过 I/O复用程序监控客户端请求事件，收到事件后通过任务分派器进行分发。针对建立连接请求事件，通过 Acceptor 处理，并建立对应的 handler 负责后续业务处理，针对非连接事件，Reactor 会调用对应的 handler 完成 read-\u0026gt;业务处理-\u0026gt;write 处理流程，并将结果返回给客户端，整个过程都在一个线程里完成。\nRedis 是基于 Reactor 单线程模式来实现的，IO多路复用程序接收到用户的请求后，全部推送到一个队列里，交给文件分派器。对于后续的操作，和在 reactor 单线程实现方案里看到的一样，整个过程都在一个线程里完成，因此 Redis 被称为是单线程的操作。\n我们平时说的Redis单线程快是指它的请求处理过程非常地快！在单线程中监听多个Socket的请求，在任意一个Socket可读/可写时，Redis去读取客户端请求，在内存中操作对应的数据，然后再写回到Socket中。\n单线程的好处：\n 没有了访问共享资源加锁的性能损耗 开发和调试非常友好，可维护性高 没有多个线程上下文切换带来的额外开销，不是没有，是减少了  单线程不是没有缺点，其实缺点也是很明显的，如果前一个请求发生耗时比较久的操作，那么整个Redis就会阻塞住，其他请求也无法进来，直到这个耗时久的操作处理完成并返回，其他请求才能被处理到，但是redis使用的Reactor 单线程模式来实现的可以缓解这种情况。\n 在Redis 4.0之后的版本，引入多线程，而这个多线程是只的异步释放内存，它主要是为了解决在释放大内存数据导致整个redis阻塞的性能问题，单机redis如果处理大数据请求时还是会出现瓶颈，但是redis有集群高可用解决方案可以解决，主节点只负责写，从节点负责读，io复用先写到这里，集群高可用我会另外在出一篇文章。\n    写时拷贝  有了高效的数据结构和io多路模型，目前能解决数据访问效率问题，但是redis为了保证了数据不丢失有快照机制，说到快照那么会操作磁盘，redis怎么解决的在数据操作的时候并且还能保证数据记录完整性的？不影响数据访问效率的呢？\n答案是用了写时复制技术，什么是写时复制？如果你是一个科班的或者你的操作系统学的不错的话，这个问题很清楚。\n在操作系统设计中进程的内存可分为 虚拟内存 和 物理内存，什么是虚拟内存？你可以去看我上一篇文章Virtual Memory。redis会从主进程中通过fork()系统调用，创建一个子进程，将父进程的 虚拟内存 与 物理内存 映射关系复制到子进程中，并将设置内存共享的，子进程只负责将内存里面数据写入到rdb进行持久化操作，如果在操作的时候主进程对内存修改了，使用写时拷贝技术，将对应的内存创建一个副本然后进行写入持久化。\n如上图主进程则提供服务，只有当有人修改当前内存数据时，才去复制被修改的内存页，用于生成快照。\n   管道通讯  除了本地服务器内存和数据结构的操作影响客户端读写效率的还有网络原因。redis的通讯协议是用一种文件协议，有兴趣自己去研究研究吧，我这里不打算写。每次客户端操作的时候，命令和元数据都被打包成redis协议进行传输到服务器上。\n按照这样那每个命令的执行时间：客户端发送时间 + 服务器处理和返回时间 + 一个网络来回的时间。\n从上图可以看出来如果每操作一条命令，那么就要执行一次网络io，如果客户端频繁操作数据那么就频繁网络操作，这个过程也是非常耗时的，影响性能的。redis在客户端程序中做了一些优化引入了一个管道（pipelining）概念。\n管道会把多条无关命令批量执行，以减少多个命令分别执行带来的网络交互时间，在一些批量操作数据的场景。\n   小结  简单始于复杂！，别看客户端就几个简单api call的事情，这后面还有很多设计值得去学习，看完这篇八股文你或许对redis高性能有新的认识了，不要小看某些细节优化和解决方案选型，有时候可以带来明显性能提升。当然这篇文章没有把redis设计写完，例如还有aof的内核文件描述符映射，异步写数据到硬盘上，零拷贝技术等等。。。。后续文章将会更新redis高可用是怎么做到的？\n","date":"Nov 04","permalink":"http://blog.ibyte.me/post/why-is-redis-high-performance/","tags":null,"title":"Why Is Redis High Performance"},{"categories":null,"contents":"   Current Limiting  在编写系统时候有时候我们的系统在设计的时候就已经估算到了最大请求负载了，如果大量的请求超过系统所能承受着的值时，那么系统可能随时挂掉，所有聪明程序员就想到了请求限流来控制系统的可用和稳定性。\n   滑动窗口限流  滑动窗口算法将一个大的时间窗口分成多个小窗口，每次大窗口向后滑动一个小窗口，并保证大的窗口内流量不会超出最大值，这种实现比固定窗口的流量曲线更加平滑。\n以系统限制用户行为为例子，比如一秒内进行某个操作5次，这种行为应该进行限制，滑动窗口就是记录一个滑动的时间窗口内的操作次数，操作次数超过阈值则进行限流。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public boolean isActionAllowed(String userId, String actionKey, int period, int maxCount) { // 生成唯一的key  String key = String.format(\u0026#34;hist:%s:%s\u0026#34;, userId, actionKey); long nowTs = System.currentTimeMillis(); // 使用管道  Pipeline pipe = jedis.pipelined(); pipe.multi(); // 添加当前操作当zset中  pipe.zadd(key, nowTs, \u0026#34;\u0026#34; + nowTs); // 整理zset，删除时间窗口外的数据 符合条件的保留  pipe.zremrangeByScore(key, 0, nowTs - period * 1000); // 目前窗口内有多少个操作  Response\u0026lt;Long\u0026gt; count = pipe.zcard(key); // 在生命周期上加一  pipe.expire(key, period + 1); pipe.exec(); pipe.close(); // 是否达到阀值  return count.get() \u0026lt;= maxCount; }      漏捅算法  露桶算法的核心思想，就把请求进行缓冲，防止大规模数量积的请求同时冲垮系统，如下图：\n每外来的请求都会被放到一个缓冲区也就是桶里面，如果缓冲区已经满了，那么新来的请求可能被拒绝，而缓冲区里面的请求则在符合系统设计负载的速率下进行放出，类似于一个队列一样。\n在redis中官方没有提供相关的实现而是通过第三方的插件进行完成这个算法的，redis-cell是4.0版本提供一个限量模块，作者是来自redis labs的itamar haber，使用的rust语言编写的，使用很简单就API call事情，有兴趣读者可以去看看，本文就水了一篇，溜了。。。\n1 2 3 4 5 6 7  CL.THROTTLE user123 15 30 60 1 ▲ ▲ ▲ ▲ ▲ | | | | └───── apply 1 token (default if omitted) | | └──┴─────── 30 tokens / 60 seconds | └───────────── 15 max_burst └─────────────────── key \u0026#34;user123\u0026#34;   如果要准确来说redis-cell的实现是令牌桶而非是漏桶算法，还是有差距的！！！！\n   其他   https://github.com/brandur/redis-cell  ","date":"Oct 28","permalink":"http://blog.ibyte.me/post/redis-current-limiting/","tags":null,"title":"Redis Current Limiting"},{"categories":null,"contents":"   Hyperloglog  上一篇文章HLL基础部分介绍了HLL一些相关理论知识，里面的抛硬币游戏，硬币正反两面，如果用计算机里面的数据表示的话，完全可以使用0和1，1表示正面，0表示反面。\nHLL常用于去重场景，HLL 算法需要完整遍历所有元素一次，而非多次或采样，算法只能计算集合中有多少个不重复的元素，不能给出每个元素的出现次数或是判断一个元素是否之前出现过，多个使用 HLL 统计出的基数值 可以融合。\nHLL的空间只会和精度有关，下面的后面不同的数字代表着不同的精度，数字越大，精度越高，占用的空间也越大。\n 上一篇文章HLL基础部分介绍了HLL一些相关理论知识，里面的抛硬币游戏，你非常幸运，第一次进行这个实验就连抛了 20 次正面，你进行了很多次这个实验才得到了这个记录，这就会导致错误的预估，改进的方式是请 10 位不同的人进行这项实验，这样就可以观察到更多的样本数据，降低出现上述情况的概率，这就是 HLL 算法的核心思想。\n HLL实现原理的话，当输入一个元素的时候，会把元素通过Jenkins hash function（当然这里也可以用其他hash算法）转成哈希值然后再转换成01表示的二进制数据。\n有了bit位值后，里面的0和1就可以表示某个事件结果的两种状态，例如正反面。有这些就可以找出每个位串上第一个最晚1出现的位置并且记录下来，并且来根据这个1来估算这些哈希值中不重复的个数。\n例如有集合为[010, 100, 001], 集合中元素的第一个 1 出现的位置分别为 2, 1, 3，可以得到里面最大的值为 3，故该集合中第一个1出现的最晚的位置为 3因为每个位置上出现1的概率都是 1/2，所以我们可以做一个简单的推断，该集合中有 8 个不重复的元素。\n这种简单的推断计算出来集合的基数值是有较大的偏差，为了减少误差，HLL 通过多次的进行试验来减少误差，HLL设计者使用了分桶的思想。\n如上图，该 hash 值的后 10 位的 bit 值是 0000001001，转成十进制是 9，对应第 9 号桶，而该值第一个1出现的位置是第6位，比原先 9号桶中的数字大，故把 9 号桶中的数字更新为 6。\n为什么是取后10位，这是是取决于结果的精确度，HLL算法的精度就越高，HLL(10) 有 1024(2^10) 个桶，HLL(16)有 65536(2^16) 个桶，桶的个数越多，所占用的空间也会越大。\n其实我这里写的还是比较简单的，省略了一些细节，真实的 HLL 算法的完整描述见上图，这边的重点是计算桶中平均数时使用调和平均数，调和平均数的优点是可以过滤掉不健康的统计值，使用算术平均值容易受到极值的影响。\n例如：求一个Google L3员工和一个 Google L6 的评价工资，如果使用传统的算法计算，计算两个相加然后/个数。\n而调和平均数计算如下：\n1  采用调和平均数的方式就是：2/(1/1000+1/30000)≈1935.484     Redis  分桶过程：抽象到计算机存储中去，就是存储的是一个以单位是比特(bit)，长度为 L 的大数组 S ，将 S 平均分为 m 组，注意这个 m 组，就是对应多少轮，然后每组所占有的比特个数是平均的，设为 P。\n1 2 3  L = S.length L = m * p 以 K 为单位，S 占用内存 = L / 8 / 1024   在Redis中HyperLogLog设置为：m=16834，p=6，L=16834 * 6，所以占用内存为=16834 * 6 / 8 / 1024 = 12K。\n","date":"Oct 25","permalink":"http://blog.ibyte.me/post/hyperloglog/","tags":null,"title":"Hyperloglog"},{"categories":null,"contents":"   一个关于统计学的问题  说Hyperloglog之前，我得先写一些它的由来。设想一下，某某地方举办了一场技术交流活动，工作人员需要统计一下这个活动当天有多少的人参加？这个需求就是一个简单的统计的需求，解决方法有很多种，例如：活动举办方在会场门口设置一个签到处，每来一个参会者记录一下，最后统计一下人数就可以了。这是一个很简单问题，当时某一天作为开发的我，接到一个来自产品需求，要我统计一下在双十一1天内的某一个页面的UV（Unique Visitors）？，那么问题来了？怎么解决？\n了解这个问题之前先说一下uv统计标准：独立访客UV指不同的用户，通过互联网访问同一个网页或产品的独立触发用户数。\n假设一个场景: 今天爸爸、妈妈、儿子三人通过三个账号访问了某宝网页，则UV=3， 这里需要提一点：独立UV是按浏览器cookie为依据。只要cookie不清楚，3个人在0:00—24:00内用同一个浏览器不同的账号登陆，只会算作一个UV。\n如图3个不同账户但是通过同一台电脑的浏览器访问的，如果默认以cookie作为标准的话，没有清理cookie的话，那么只会算一个uv。\n那么有开发经验的肯定会说简单啊，用hashmap或者用set集合\u0026hellip;看似是一个简单问题，问题虽不难，但当参与问题中的变量达到一定数量级的时候，再简单的问题都会变成一个难题。假设日活用户达到百万或千万以上级别的话，我们采用 HashMap 的做法，就会导致程序中占用大量的内存，并且都是在并行的操作记录，还可能要考虑锁颗粒度问题，显然有经验的老司机会直接否决🙅这种方案。\n   HyperLogLog  看了什么的问题，那有木有什么好的解决方案？ 有肯定是有的：B+ tree，Bitmap，在redis中就有造好的轮子的HyperLogLog概率数据结构算法，在redis中使用也就是3个api的事情：pfadd、pfcount、pfmerge。但是想深挖下去这个东西属实有点复杂，会涉及到一些数学上的东西，正好笔者我也看了看实现，顺便就写了这篇文章，HyperLogLog这个是由下面👇这个肥宅在他的论文中提出的，对可能这就是国外搞学术的大佬吧，不过可惜的是大佬在 2011年3月22日就去世了，不过他留下的HyperLogLog还是很值得研究的。\nHLL的特点就是能花较低的内存占用统计海量的数据，但是缺点也有代码实现比较难，有一定的误差，如果要统计的100%的准确性，还是要考虑其他方案或者通过数学计算算出误差值（负载因子）。\n在redis实现的HyperLogLog中能用12k内存就能统计2^64个数据，我表示很震撼。。。怎么做到的？？？\n挖槽这是怎么做到的？看了一下那篇论文：http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf\n   伯努利试验证明  在说HLL之前得先了解一下伯努利试验!\n 伯努利试验是数学概率论中的一部分内容，它的典故来源于抛硬币游戏。 实验的内容：在同一个条件下重复地、各次之间相互独立地进行的一种试验，但是实验的结果只要两种结果，每次实验结果只会是两种结果中一个，然后在相同条件下重复做n次的试验称为n次独立重复试验，独立性是只各次试验的结果不会受其他实验结果的影响。\n 次数较少的实验是没有意义的，只要当实验次数达到一定数量，就和微积分一样，短时间是看不出来差异的，但是如果把时间线拉长，那么差异就出来了。\n实验过程： 硬币拥有正反两面，一次的上抛至落下，最终出现正反面的概率各自都是50%，假设一直抛硬币，直到它出现正面为止，我们记录为一次完整的试验，间中可能抛了一次就出现了正面，也可能抛了n次才出现正面，不管抛出多少次，只要出现了正面，就记录为一次试验。\n重复不断这个过程，假设这个多次为n次，就意味着出现了n次的正面。假设每次伯努利试验所经历了的抛掷次数为k，第一次伯努利试验，次数设为k1，以此类推，第n次对应的是kn，在实验过程中肯定会出现抛出n才能出现一次正面，那么称这个为k_max，代表抛了最多的次数。\n经过反复实验得出结果：\n N次实验抛出的次数不会大于k_max N次实验最少有一次的次数是k_max  当有了这些结论之后，发现在n和k_max中存在估算关联：n = 2^(k_max)，当然需要大量的数据和实验次数证明，如果需要深入挖掘其中的奥秘，那么还会涉及到数学中的概率和统计的方法才能推导和验证这种关联关系。。。。\n1 2 3 4  第一次: 抛了3次出正面，此时 k=3，n=1 第二次: 抛了2次出正面，此时 k=2，n=2 第三次: 抛了6次出正面，此时 k=6，n=3 第n 次：抛了20次出正面，此时我们估算， n = 2^20   看上面的实验如果套用这个估算关系公式的话，那么结果是：上面例子中实验组数共3组，那么 k_max = 6，最终 n=3，我们放进估算公式中去，明显： 3 ≠ 2^6不成立的，但是证明了数据次数越少，意义就不大，发挥不了作用，就存在一定的误差值。\n通过上面一系列的推导，又会得出一个结论就是，如果我每轮实验的次数越多，那么结果偏差就会越小，但是还有有偏差的存在。那么可不可以搞一个多轮的次数测试，例如搞1000次，然后再去取每轮的k_max，然后把k_max平摊到轮数上，就能算出n。\n但是结果还是有偏差的，那怎么办？可以通过少量的测试观察结果误差，适当用修正因子做计算提高准确率，然后又演进出了一种LogLog的估算公式：\n上面的DVLL对应的就是n，constant为修正因子具体值是不定的，自定义设置，可以通过少量的测试观察结果误差，m代表的是试验的轮数，头上有一横的R就是平均数：(k_max_1 + ... + k_max_m)/m。\n   小结  本文整理一下LogLog相关基础理论，但是没有写完，后面更新下篇文章会讲redis的hll具体实现细节，HyperLogLog是由Loglog优化改进过来的，所以本篇先写到这。\n","date":"Oct 25","permalink":"http://blog.ibyte.me/post/bernoulli-experiment/","tags":null,"title":"Bernoulli Experiment"},{"categories":null,"contents":"   什么是逻辑内存  什么是逻辑内存？把物理内存通过程序进行虚拟化出来的内存映射，这就称之为逻辑内存或虚拟内存。内存对于程序来说非常重要，当然大部分现在如果你不搞操作系统或者一些特定领域的开发一般很少了解。内存对于计算机来说非常宝贵的东西，现在的程序员只会在这些基础之上进行开发东西，内存管理是交给操作系统进行管理的。\n   内存管理  对于操作系统来说怎么分配内存，怎么去给每个不同程序分配内存，管理数据，怎么隔离内存，怎么不让程序a去访问程序b的内存，内存不够了会怎么样？这些问题都是需要操作系统解决的。\n假设计算机内存是4GB，这里需要运行4个程序，如图：\n如图内存只要4GB但是需要运行的程序内存总和还要大于4GB，只能满足ABC这3个程序的运行，这时需要运行D那么就要等着，操作系统回收内存再去看看有木有合适的位置满足运行条件。\n但是这又出现一个新的问题，如图：\n当操作系统回收了A和C程序所占用的内存时，发现这块内存不是连续的，而D程序需要一块连续的内存才能正常跑起来，这里问题就是为什么需要有virtual memory的原因之一了。\n   Virtual Memory  有了这些使用上的问题，然后就会出现了Virtual Memory这种技术，把物理加一层映射，而映射这一层就是现在的Virtual Memory，下面我画了一张图：\n通过这种方式把物理内存虚拟化成一个虚拟化的内存，从而达到高效的利用，虚拟地址抽象不能在应用的运行过程中造成明显的开销，也不会占用过多的物理内存资源，有效的动态规划利用物理内存。虚拟内存可以完全把不同程序的内存隔离开来，让程序无法访问到其他程序的内存，安全性高。透明性，程序开发者也无限关系程序在运行的时候内存是否够用，感觉不到虚拟内存的存在。\n虚拟内存划分规则有很多种，例如分段机制和分页机制这里我也没有打算写，后面有空再写写分段和分页区别和缺页异常和内存页替换策略，怎么在物理内存不够用的情况下去解决这个问题等...。\n   其他  如果对相关内容感兴趣，可以去看看上海交大陈海波教授的操作系统课程，地址：https://ipads.se.sjtu.edu.cn/courses/os/，当然这个部分内存只支持内网访问。\n","date":"Oct 08","permalink":"http://blog.ibyte.me/post/virtual-memory/","tags":null,"title":"Virtual Memory"},{"categories":null,"contents":"切片是Golang里面一个复合数据类型，可以把它看做为一个可变长度的数组，和动态数组一样，在创建的时候我们可以指定容量大小，如果不够了，它还能指定扩容，基本的crud没有什么可说的本篇文章将写写切片底层的实现。\n   slice struct  其实slice在底层就是一个struct声明一个结构体，结构如下：\n1 2 3 4 5  type slice struct { array unsafe.Pointer len int cap int }   slice本身一个结构体里面包含了array和len和cap成员变量，array是一个指针指向真正存储数据的内存头元素地址，len记录着当前实际的元素个数，cap记录当前切片的容量，如上图所示。\n   append expansion  在说append扩容机制之前，先看一个下面的题目，最终输出什么？？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  package main import ( \u0026#34;fmt\u0026#34; ) func main() { array := [...]int{1,2,3,4,5} s1 := append(array[:3],array[4:]...) s2 := s1 s1 = append(s1,[]int{6,7}...) test(s2) test(s1) fmt.Println(s1,s2) } func test(s []int) { s = append(s,10) for i := range s { s[i]*=2 } }   估计大多数人肯定会秒回答说[1 2 3 5 5 6 7] [1 2 3 5 5]，如果回答这个就说明你连go里面函数参数是值传递还是引用传递都没有搞清楚，而且你对append也没有搞清楚。\n上面代码运行正确的答案是[2 4 6 10 12 14] [2 4 6 10]！\n为什么会这样？这个首先在Go语言中的所有东西都是以值传递的，也就是说，一个函数总是得到一个被传递的东西的副本，就像有一个赋值语句将值赋给参数一样。\n上图就是整个append扩容过程，首先检测原始的array底层的那个数组容量够不够，如果不够就会先申请一块新的内存，当然这个扩容大小有相应的策略的，我画的这幅方便理解，所以我这里就当原始数量的*2进行扩容。扩容之后把旧切片的元素复制到新的切片中，然后将相应的添加的元素追加进去即可。\n了解这些就很方便理解为什么？？上面结果是[2 4 6 10 12 14] [2 4 6 10]了，首先我将s1赋值给了s2，s2和s1共用一块底层的元素内存，然后将s1进行了append操作，这一操作会触发扩容机制，所有在扩容之后s2和s1底层数组完全是不一样的！test(s []int)又是值拷贝，拷贝也是底层的指针，所有操作还是一块内存，就会影响到外面的，这里的拷贝只会影响到unsafe.Pointer指针类型，len和cap则是值拷贝。\n","date":"Sep 26","permalink":"http://blog.ibyte.me/post/go-slice-expansion-mechanism/","tags":null,"title":"Go Slice Expansion Mechanism"},{"categories":null,"contents":"本页面是本博主个人平时整理的一些计算机科学专业视频学习资料，整理放在下面方便大家浏览，希望对大家有帮助。\n   资料名称 链接     数据库基础 哔哩哔哩视频   数据结构基础 哔哩哔哩视频   操作系统基础 上海交通大学-陈海波    ","date":"Sep 24","permalink":"http://blog.ibyte.me/post/computer-science-learning/","tags":null,"title":"Computer Science Learning"},{"categories":null,"contents":"   概 述  在开发过程中，作为一个crud boy来说会使sql来操作数据库增删改查是必不可少的，这篇文章将写写日常开发中常用的sql语句。数据是一个抽象的的定义，所谓的数据库就是把一些元数据通过特定规律整理到一起管理起来，方便通过他特定DDL，DCL，DML这些特定的语句来方便管理数据。\n DDL (data definition languages) 方便开发者通过SQL来定义存储的数据格式，组织数据。 DML (data manipulation languages) 允许用户对数据进行create、delete、insert、updated操作。 DCL (data control languages) 可以来管理用户对数据的访问操作权限，例如检索，更新，删除 \u0026hellip;     查询语句  在日常开发过程中查询数据是应用场景最多的，查询就要使用select关键字，如下：\n1  select*fromtableName;  例如有一个表结构如下：\n上面是查询整张表的所有字段数据，如果需要筛选就需要制定其field name如下：\n1  selectnameas\u0026#34;用户名\u0026#34;fromTableName;  并且上面使用了as关键字并进行了别名，查询出来数据就按照别名进行展示。\n如果想查询指定的数据,就要使用where子语句，如下：\n1  select*fromTableNamewhereID=1;  那么上的SQL语句查询出来的结果就是上图中ID等于1的一条数据。\n如果需要整理结果集去重复的话在前面加入distinct关键字，就可以去重了。\n   查询过滤  有时候我们通过条件查询到的数据需要进行其他筛选，这个时候我们就要使用到limit或者order by进行过滤或者重新整理了。\n例如我要查询表中年龄最小那个用户的名字，这里不排除年龄是重复的情况，如下：\n1  selectusernamefromTableNameorderbyagedesclimit1;  上面就是对 age进行降序然后取一条数据。\n1  select*fromTableNameorderbyageASC;  对表进行按照age升序排序整理输出结果。\nlimit支持几种方式，limit 2,5意思是从第2行开始，往后查询5条数据，limit 2 offset 3意思是从3开始往后查询2条数据。\n有时候我们查询需要使用运算符，sql也是支持运算符的\u0026lt;、\u0026gt;、\u0026lt;\u0026gt;、\u0026lt;=、\u0026gt;=、!\u0026lt;、!\u0026gt;，这些都可以加在条件语句中。\n字段类型也支持数学运算例如：\n1  select*fromTableNamewhere(age+10)=32;  上面一条语句就是查询age加10以后等于32的数据。\n有时候我们需要对这个表进行多个条件限制查询，我们可能就需要使用到OR或者AND进行条件关联查询了，例如：\n1 2 3 4  selectusers.mobile,user_address.mobileas\u0026#34;用户订单手机号\u0026#34;,user_address.addressfromuser_address,userswhereuser_address.user_id=users.user_id;  上面这个多表关联查询了，条件是user_address表的id要和users表的id相等的数据查询出来。\n多个条件可以使用and关联起来组成一个条件，例如：\n1  selectBookNameas书名,Priceas价格,WriterAS作者frombookinfoWHEREMONTH(pDate)=9andYEAR(pDate)=2021;  查询图书表里面的出版月份是9月的并且是2021年的9月出版的图书信息。\n1  select*fromTableNamewhereusername=\u0026#39;Leon Ding\u0026#39;orage=22;  上面使用or满足任意一边条件即可就能查询到数据。\n还有一种就是查询在某个范围内的数据，例如：\n1 2 3  select*fromgoodswherecost_pricebetween1099and2880;  上面就是查询成本价在1099-2880之间的商品信息，我们还可以使用not放在between前面，也就是取反的意思。\n多个条件或者通过多个类型来查询可以使用in关键字，例如：\n1  select*fromTableNameagein(22,18);  上面是查年龄是22和18的用户信息。\n","date":"Sep 21","permalink":"http://blog.ibyte.me/post/often-used-structured-query-languages/","tags":null,"title":"Often Used Structured Query Languages"},{"categories":null,"contents":"相信大家在开发的过程中会去编写一些数据库表对应的model，工作比较重复并且低效，本文将介绍笔者写的一个工具可以根据数据库表生产对应的model逆向工程工具。\n   什么是s2s？  s2s (sql to structure)是一款命令行数据库逆向工程工具，它可以通过数据库表生成对应的Java、Go、Rust结构体（class），后面将陆续支持更多的语言。\n   配置数据库源  s2s依赖于你的数据库，所以需要你配置好你的数据库连接信息，以便s2s会正常的运行。配置信息方法很简单你只需要在你的环境变量中加入以下信息即可。\n推荐使用开发环境的下的root用户登录，因为工具需要information_schema表的权限。\n1 2 3 4 5  #s2s 命令的数据库信息 export s2s_host=\u0026#34;127.0.0.1:3306\u0026#34; export s2s_user=\u0026#34;root\u0026#34; export s2s_pwd=\u0026#34;you db password\u0026#34; export s2s_charset=\u0026#34;utf8\u0026#34;   windows的配置此电脑-\u0026gt;属性-\u0026gt;高级系统设置-\u0026gt;环境变量，Mac和Linux则在~/.profile或者~/.zshrc中添加以上配置信息即可。\n   使用方法    你可以克隆下载本代码库，然后如果你的电脑上已经安装好了go的编译器那么就进入主目录即可使用go build命令编译生成二进制程序文件。\n  如果你觉得麻烦即可在下面列表中找到你对应的平台架构下载对应的二进制可执行文件到电脑上，如果你想在系统上随意调用你则只需要把s2s的安装目录放入你的环境变量中。\n  目前对Rust部分数据类型支持不够友好，不过不耽误使用，目前被生成的数据库表名格式必须为user_info这样的snake case这种格式！！后面会考虑修复这个bug。\n     平台 地址     Windows-x64 s2s-windows-x64.zip   Mac-x64 s2s-darwin-x64.zip   Linux-64 s2s-linux-x64.zip       内置命令  PS: 在命令行模式下按下tab键会有命令补全提示！\n   命令 使用方法     databases 显示所有数据库名   use 指定使用哪个数据库   tables 显示当前数据库所有表   gen 生成指定的表，gen 表名   info 显示数据库所有信息   exit 退出命令行模式   clear 清理屏幕内容    使用案例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146  $:\u0026gt; s2s java ______ .-----.|__ |.-----. |__ --|| __||__ --| |_____||______||_____| 🥳: You have entered the command line mode! 🥳: Press the \u0026#39;tab\u0026#39; key to get a prompt！ 🥳: Enter `exit` to exit the program! 😃:s2s\u0026gt;databases +---+--------------------+ | * | Database | +---+--------------------+ | 1 | information_schema | | 2 | emp_db | | 3 | mysql | | 4 | performance_schema | | 5 | sys | | 6 | test_db | +---+--------------------+ 😃:s2s\u0026gt;use emp_db 🤖‍: Selected as database 👉 `emp_db`！ 😃:s2s\u0026gt;tables +---+-----------+ | * | Tables | +---+-----------+ | 1 | user_info | +---+-----------+ 😃:s2s\u0026gt;gen user_info package model import java.sql.Timestamp; import java.math.BigDecimal; import java.math.BigInteger; public class UserInfo { // 用户账号  private String Account; // 用户创建时间  private Timestamp CreateTime; // 用户更新时间  private Timestamp UpdatedDate; // 用户年龄  private short Age; // 用户余额  private BigDecimal Money; // 用户ID  private BigInteger Uid; public String getAccount() { return Account; } public void setAccount(String Account) { this.Account = Account; } public Timestamp getCreateTime() { return CreateTime; } public void setCreateTime(Timestamp CreateTime) { this.CreateTime = CreateTime; } public Timestamp getUpdatedDate() { return UpdatedDate; } public void setUpdatedDate(Timestamp UpdatedDate) { this.UpdatedDate = UpdatedDate; } public short getAge() { return Age; } public void setAge(short Age) { this.Age = Age; } public BigDecimal getMoney() { return Money; } public void setMoney(BigDecimal Money) { this.Money = Money; } public BigInteger getUid() { return Uid; } public void setUid(BigInteger Uid) { this.Uid = Uid; } @Override public String toString() { return \u0026#34;user_info{\u0026#34; + \u0026#34;Account=\u0026#34; + Account + \u0026#34;,\u0026#34;+ \u0026#34;CreateTime=\u0026#34; + CreateTime + \u0026#34;,\u0026#34;+ \u0026#34;UpdatedData=\u0026#34; + UpdatedDate + \u0026#34;,\u0026#34;+ \u0026#34;Age=\u0026#34; + Age + \u0026#34;,\u0026#34;+ \u0026#34;Money=\u0026#34; + Money + \u0026#34;,\u0026#34;+ \u0026#34;Uid=\u0026#34; + Uid + \u0026#34;,\u0026#34;+ \u0026#34;}\u0026#34;; } } 😃:s2s\u0026gt;exit 🤖‍: Bye👋 :)      导入包  本库支持你二次开发使用，你只需要导入本包即可在你的代码中进行扩充开发，但是目前仅支持go语言！\n 下载  1  go get -u github.com/higker/s2s   导入并且使用  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  package main import ( \u0026#34;github.com/higker/s2s/core/lang/java\u0026#34; \u0026#34;github.com/higker/s2s/core/db\u0026#34; ) func main() { // 创建一个Java的代码生成器  structure := java.New() // 数据库连接信息  if err := structure.OpenDB( \u0026amp;db.Info{ HostIPAndPort: os.Getenv(\u0026#34;s2s_host\u0026#34;), // 数据库IP  UserName: os.Getenv(\u0026#34;s2s_user\u0026#34;), // 数据库用户名  Password: os.Getenv(\u0026#34;s2s_pwd\u0026#34;), // 数据库密码  Type: db.MySQL, // 数据库类型 PostgreSQL Oracle  Charset: os.Getenv(\u0026#34;s2s_charset\u0026#34;), }, ); err != nil { // Failed to establish a connection to the database!  // .... logic code  } defer structure.Close() structure.SetSchema(\u0026#34;选择数据库名\u0026#34;) // 实现了io.Writer即可  structure.Parse(os.Stdout,\u0026#34;表名\u0026#34;) }      其他  目前仅支持mysql数据库，如果有想贡献代码提issues！跟多需求： 1. 支持linux管道命令这样就可以可编程操作了，前面一个输出就是后面一个程序的输入。\n 可以帮忙点一个star✨谢谢！！！ https://github.com/auula/s2s  ","date":"Sep 16","permalink":"http://blog.ibyte.me/post/golang-database-reverse-engineering/","tags":null,"title":"Golang Database Reverse Engineering"},{"categories":null,"contents":"   lifetime寿命  Rust中的每一个引用都有一个有效的作用域，生命周期就是为这个作用域服务的，大部分生命周期编译器可以推断出来，可以是隐式的。但是如果在某些情况下编译器就无法正常推断出来了，需要我们自己手动标注，标注生命周期语法就是'a这样的语法。\n   为什么需要生命周期？  例如下面例子就是在两个字符串切片里面查找最长的那个并且返回！\n1 2 3 4 5 6 7 8  // \u0026#39;a 是指3个引用的作用域生命周期要一致 fn find_long_str\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str,y: \u0026amp;\u0026#39;a str)-\u0026gt; \u0026amp;\u0026#39;a str {ifx.len()\u0026gt;y.len(){x}else{y}}  上面我就加注了生命周期标识符，如果不加编译器会报错，原因是因为我们这个函数引用的是外部的变量，不能确定引用的变量是否已经被销毁了，那这样就是悬垂引用！\n1 2 3 4 5 6 7 8 9 10  letstr1=String::from(\u0026#34;Hello\u0026#34;);letstr2;letresult;{//let str2 = String::from(\u0026#34; World!\u0026#34;); str2=String::from(\u0026#34; World!\u0026#34;);result=find_long_str(str1.as_str(),\u0026amp;str2);}// 这里借用检测就提示 引用了已经销毁的资源了 println!(\u0026#34;{}\u0026#34;,result);  加了生命周期标识符之后，如果我把let str2 = String::from(\u0026quot; World!\u0026quot;);取消注释放在一个内部作用域里面定义，那么这时调用 find_long_str编译器就会报错，因为我在下面出了作用域还使用了find_long_str返回的结果，而这个结果可能就是str2的内容， 使用这个是违反了所有权规则的，str2离开内部作用域就被销毁了。\n在标注生命周期fn find_long_str\u0026lt;'a\u0026gt;(x: \u0026amp;'a str, y: \u0026amp;'a str) -\u0026gt; \u0026amp;'a str之后编译器就知道输入参数和返回参数生命周期是要一致的，并且返回值生命周期肯定是取生命周期最短的那个的。\n   总结   生命周期是确保被引用的值是有效的。 引用的生命周期肯定是小于或者等于资源所有者的。 如果是在函数里面创建的资源，应该是直接返回其所有权，而不是引用。 每个生命周期标注都有不同的生命周期，如果有输入的生命周期，那么输出的生命周期也是一致的。 self的生命周期会被赋给输出的生命周期。     其他   当然上面是我刚刚入坑总结话，有错误地方望大佬指教！ https://play.rust-lang.org/?version=stable\u0026amp;mode=debug\u0026amp;edition=2018\u0026amp;gist=a868aa030fa934b22cd770727f42724d  ","date":"Sep 16","permalink":"http://blog.ibyte.me/post/rust-lifetime/","tags":null,"title":"Rust Lifetime"},{"categories":null,"contents":"   什么是智能指针？  在Rust中智能指针有很多种，用大白话说就是一个数据结构，实现了一些特殊的trait从而达到某种特性和功能，然后去管理某块内存上的数据，相当于一个盒子一样包装一层，这篇文章将介绍一下Box。\n   Deref  Deref这个trait只要实现了它那么你自定义的结构体，就可以使用*解引用拿取你结构体里面所包装的数据，熟悉Rust都知道*是用来解引用的，下面的I32Box(i32)就是实现了Deref从而达到直接使用*拿取出内部的数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  usestd::ops::Deref;struct I32Box(i32);// impl Deref implDerefforI32Box{type Target=i32;fn deref(\u0026amp;self)-\u0026gt; \u0026amp;Self::Target{\u0026amp;self.0}}implI32Box{fn new(v:i32)-\u0026gt; Self{I32Box(v)}}fn main(){letn=I32Box::new(1024_i32);println!(\u0026#34;{}\u0026#34;,*n);}     Drop  Rust里面有drop函数，也有一个Drop的trait同样如果自定义的结构体实现这个Drop，那么就你变量离开作用域的时候执行自定义Drop的方法的逻辑。\n1 2 3 4 5  implDropforI32Box{fn drop(\u0026amp;mutself){println!(\u0026#34;啊，挂了，I32Box({:?})被清理了！\u0026#34;,self.0)}}  例如为I32Box实现Drop的drop函数，运行：\n1 2 3 4 5 6 7  Compiling playground v0.0.1 (/playground) Finished dev [unoptimized + debuginfo] target(s) in 1.33s Running `target/debug/playground` 1024 啊，挂了，I32Box(1024)被清理了！   当I32Box离开自己的作用域那么它会自动执行drop方法。\n   Box  有了这些特殊的trait基础之后，智能指针就自身有了这种行为了，就能管理内部的数据了。\nBox智能指针它管理的数据，内存是分配在heap上的，可以在堆上存储我们自定义的的数据，而把指针放在栈上。有这些特性，我们就可以使用Box实现一个类似动态数组的数据结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  #[derive(Debug)]struct DynamicArr{cap:i32,len:i32,data:Box\u0026lt;[i32]\u0026gt;,}implDynamicArr{fn new()-\u0026gt; DynamicArr{DynamicArr{cap:10,len:0,data: Box::new([0;10]),}}fn push(\u0026amp;mutself,v:i32){// expansion ifself.len==self.cap{// add 10 capacity letmutnew_arr=Box::new([0;20]);letmutindex=0;forvinself.data.iter(){new_arr[index]=*v;index+=1;}self.data=new_arr;self.cap+=indexasi32;}self.data[self.lenasusize]=v;self.len+=1;}}fn main(){letmutarr=DynamicArr::new();forvin0..16{arr.push(v);}println!(\u0026#34;{:#?}\u0026#34;,arr)}  例如上面通过Box智能指针实现一个自定义DynamicArr结构，它在我们添加数组的时候会检查容量，当达到阈值就会发生expansion，上面只是个小demo，还有bug，只是为了演示Box智能指针的使用。\n   其他   I32Box DynamicArr  ","date":"Sep 16","permalink":"http://blog.ibyte.me/post/rust-box-pointer/","tags":null,"title":"Rust Box Pointer"},{"categories":null,"contents":"   前 言   在开发高并发系统时，我们可能会遇到接口访问频次过高，为了保证系统的高可用和稳定性，这时候就需要做流量限制，你可能是用的 Nginx 这种 Web Server 来控制请求，也可能是用了一些流行的类库实现。限流是高并发系统的一大杀器，在设计限流算法之前我们先来了解一下它们是什么。\n    限 流  限流的目的是通过对并发访问请求进行限速，或者对一个时间窗口内的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务、排队或等待、降级等处理。通过对并发（或者一定时间窗口内）请求进行限速来保护系统，一旦达到限制速率则拒绝服务（定向到错误页或告知资源没有了）、排队等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据）。\n如 图:\n如图上的漫画，在某个时间段流量上来了，服务的接口访问频率可能会非常快，如果我们没有对接口访问频次做限制可能会导致服务器无法承受过高的压力挂掉，这时候也可能会产生数据丢失，所以就要对其进行限流处理。\n限流算法就可以帮助我们去控制每个接口或程序的函数被调用频率，它有点儿像保险丝，防止系统因为超过访问频率或并发量而引起瘫痪。我们可能在调用某些第三方的接口的时候会看到类似这样的响应头：\n1 2 3  X-RateLimit-Limit:60//每秒60次请求X-RateLimit-Remaining:22//当前还剩下多少次X-RateLimit-Reset:1612184024//限制重置时间  上面的 HTTP Response 是通过响应头告诉调用方服务端的限流频次是怎样的，保证后端的接口访问上限。为了解决限流问题出现了很多的算法，它们都有不同的用途，通常的策略就是拒绝超出的请求，或者让超出的请求排队等待。\n一般来说，限流的常用处理手段有：\n 计数器 滑动窗口 漏桶 令牌桶     计数器   计数器是一种最简单限流算法，其原理就是：在一段时间间隔内，对请求进行计数，与阀值进行比较判断是否需要限流，一旦到了时间临界点，将计数器清零。 这个就像你去坐车一样，车厢规定了多少个位置，满了就不让上车了，不然就是超载了，被交警叔叔抓到了就要罚款的，如果我们的系统那就不是罚款的事情了，可能直接崩掉了。\n  可以在程序中设置一个变量 count，当过来一个请求我就将这个数 +1，同时记录请求时间。 当下一个请求来的时候判断 count 的计数值是否超过设定的频次，以及当前请求的时间和第一次请求时间是否在 1 分钟内。 如果在 1 分钟内并且超过设定的频次则证明请求过多，后面的请求就拒绝掉。 如果该请求与第一个请求的间隔时间大于计数周期，且 count 值还在限流范围内，就重置 count。  代码实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66  package main import ( \u0026#34;log\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) type Counter struct { rate int //计数周期内最多允许的请求数  begin time.Time //计数开始时间  cycle time.Duration //计数周期  count int //计数周期内累计收到的请求数  lock sync.Mutex } func (l *Counter) Allow() bool { l.lock.Lock() defer l.lock.Unlock() if l.count == l.rate-1 { now := time.Now() if now.Sub(l.begin) \u0026gt;= l.cycle { //速度允许范围内， 重置计数器  l.Reset(now) return true } else { return false } } else { //没有达到速率限制，计数加1  l.count++ return true } } func (l *Counter) Set(r int, cycle time.Duration) { l.rate = r l.begin = time.Now() l.cycle = cycle l.count = 0 } func (l *Counter) Reset(t time.Time) { l.begin = t l.count = 0 } func main() { var wg sync.WaitGroup var lr Counter lr.Set(3, time.Second) // 1s内最多请求3次  for i := 0; i \u0026lt; 10; i++ { wg.Add(1) log.Println(\u0026#34;创建请求:\u0026#34;, i) go func(i int) { if lr.Allow() { log.Println(\u0026#34;响应请求:\u0026#34;, i) } wg.Done() }(i) time.Sleep(200 * time.Millisecond) } wg.Wait() }   OutPut:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  2021/02/01 21:16:12 创建请求: 0 2021/02/01 21:16:12 响应请求: 0 2021/02/01 21:16:12 创建请求: 1 2021/02/01 21:16:12 响应请求: 1 2021/02/01 21:16:12 创建请求: 2 2021/02/01 21:16:13 创建请求: 3 2021/02/01 21:16:13 创建请求: 4 2021/02/01 21:16:13 创建请求: 5 2021/02/01 21:16:13 响应请求: 5 2021/02/01 21:16:13 创建请求: 6 2021/02/01 21:16:13 响应请求: 6 2021/02/01 21:16:13 创建请求: 7 2021/02/01 21:16:13 响应请求: 7 2021/02/01 21:16:14 创建请求: 8 2021/02/01 21:16:14 创建请求: 9   可以看到我们设置的是每200ms创建一个请求，明显高于1秒最多3个请求的限制，运行起来之后发现编号为 2、3、4、8、9 的请求被丢弃，说明限流成功。\n那么问题来了，如果有个需求对于某个接口 /query 每分钟最多允许访问 200 次，假设有个用户在第 59 秒的最后几毫秒瞬间发送 200 个请求，当 59 秒结束后 Counter 清零了，他在下一秒的时候又发送 200 个请求。那么在 1 秒钟内这个用户发送了 2 倍的请求，这个是符合我们的设计逻辑的，这也是计数器方法的设计缺陷，系统可能会承受恶意用户的大量请求，甚至击穿系统。\n如下图:\n这种方法虽然简单，但也有个大问题就是没有很好的处理单位时间的边界。\n   滑动窗口  滑动窗口是针对计数器存在的临界点缺陷，所谓 滑动窗口（Sliding window） 是一种流量控制技术，这个词出现在 TCP 协议中。滑动窗口把固定时间片进行划分，并且随着时间的流逝，进行移动，固定数量的可以移动的格子，进行计数并判断阀值。\n如 图：\n上图中我们用红色的虚线代表一个时间窗口（一分钟），每个时间窗口有 6 个格子，每个格子是 10 秒钟。每过 10 秒钟时间窗口向右移动一格，可以看红色箭头的方向。我们为每个格子都设置一个独立的计数器 Counter，假如一个请求在 0:45 访问了那么我们将第五个格子的计数器 +1（也是就是 0:40~0:50），在判断限流的时候需要把所有格子的计数加起来和设定的频次进行比较即可。\n那么滑动窗口如何解决我们上面遇到的问题呢？来看下面的图：\n当用户在0:59 秒钟发送了 200 个请求就会被第六个格子的计数器记录 +200，当下一秒的时候时间窗口向右移动了一个，此时计数器已经记录了该用户发送的 200 个请求，所以再发送的话就会触发限流，则拒绝新的请求。\n其实计数器就是滑动窗口啊，只不过只有一个格子而已，所以想让限流做的更精确只需要划分更多的格子就可以了，为了更精确我们也不知道到底该设置多少个格子，格子的数量影响着滑动窗口算法的精度，依然有时间片的概念，无法根本解决临界点问题。\n 相关算法实现 github.com/RussellLuo/slidingwindow     漏 桶  漏桶算法（Leaky Bucket），原理就是一个固定容量的漏桶，按照固定速率流出水滴。用过水龙头都知道，打开龙头开关水就会流下滴到水桶里，而漏桶指的是水桶下面有个漏洞可以出水。如果水龙头开的特别大那么水流速就会过大，这样就可能导致水桶的水满了然后溢出。\n如 图：\n一个固定容量的桶，有水流进来，也有水流出去。对于流进来的水来说，我们无法预计一共有多少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，这个桶可以固定水流出的速率（处理速度），从而达到 流量整形 和 流量控制 的效果。\n代码实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  type LeakyBucket struct { rate float64 //固定每秒出水速率  capacity float64 //桶的容量  water float64 //桶中当前水量  lastLeakMs int64 //桶上次漏水时间戳 ms  lock sync.Mutex } func (l *LeakyBucket) Allow() bool { l.lock.Lock() defer l.lock.Unlock() now := time.Now().UnixNano() / 1e6 eclipse := float64((now - l.lastLeakMs)) * l.rate / 1000 //先执行漏水  l.water = l.water - eclipse //计算剩余水量  l.water = math.Max(0, l.water) //桶干了  l.lastLeakMs = now if (l.water + 1) \u0026lt; l.capacity { // 尝试加水,并且水还未满  l.water++ return true } else { // 水满，拒绝加水  return false } } func (l *LeakyBucket) Set(r, c float64) { l.rate = r l.capacity = c l.water = 0 l.lastLeakMs = time.Now().UnixNano() / 1e6 }   漏桶算法有以下特点：\n 漏桶具有固定容量，出水速率是固定常量（流出请求） 如果桶是空的，则不需流出水滴 可以以任意速率流入水滴到漏桶（流入请求） 如果流入水滴超出了桶的容量，则流入的水滴溢出（新请求被拒绝）  漏桶限制的是常量流出速率（即流出速率是一个固定常量值），所以最大的速率就是出水的速率，不能出现突发流量。\n   令牌桶算法  令牌桶算法（Token Bucket）是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。\n我们有一个固定的桶，桶里存放着令牌（token）。一开始桶是空的，系统按固定的时间（rate）往桶里添加令牌，直到桶里的令牌数满，多余的请求会被丢弃。当请求来的时候，从桶里移除一个令牌，如果桶是空的则拒绝请求或者阻塞。\n实现代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  type TokenBucket struct { rate int64 //固定的token放入速率, r/s  capacity int64 //桶的容量  tokens int64 //桶中当前token数量  lastTokenSec int64 //桶上次放token的时间戳 s  lock sync.Mutex } func (l *TokenBucket) Allow() bool { l.lock.Lock() defer l.lock.Unlock() now := time.Now().Unix() l.tokens = l.tokens + (now-l.lastTokenSec)*l.rate // 先添加令牌  if l.tokens \u0026gt; l.capacity { l.tokens = l.capacity } l.lastTokenSec = now if l.tokens \u0026gt; 0 { // 还有令牌，领取令牌  l.tokens-- return true } else { // 没有令牌,则拒绝  return false } } func (l *TokenBucket) Set(r, c int64) { l.rate = r l.capacity = c l.tokens = 0 l.lastTokenSec = time.Now().Unix() }   令牌桶有以下特点：\n 令牌按固定的速率被放入令牌桶中 桶中最多存放 B 个令牌，当桶满时，新添加的令牌被丢弃或拒绝 如果桶中的令牌不足 N 个，则不会删除令牌，且请求将被限流（丢弃或阻塞等待）  令牌桶限制的是平均流入速率（允许突发请求，只要有令牌就可以处理，支持一次拿3个令牌，4个令牌\u0026hellip;），并允许一定程度突发流量。\n   小 结  目前常用的是令牌桶这种，本文介绍了几种常见的限流算法实现，文章撰写不易，点个关注不迷路。\n","date":"Sep 16","permalink":"http://blog.ibyte.me/post/traffic-restrictions/","tags":null,"title":"Traffic Restrictions"},{"categories":null,"contents":"   概 述  随着互联网的高速发展，信息安全问题已经成为企业最为关注的焦点之一，而前端又是引发企业安全问题的高危据点。在移动互联网时代，前端人员除了传统的 XSS、CSRF 等安全问题之外，又时常遭遇网络劫持、非法调用 API 等新型安全问题。当然，浏览器自身也在不断在进化和发展，不断引入 CSP、Same-Site Cookies 等新技术来增强安全性，但是仍存在很多潜在的威胁，这需要我们技术人员不断对系统进行“查漏补缺”。\n   废话少说，先看问题  为了模拟问题我这边用go写了2个服务端的代码，正常交易系统的API，当然这里只是为了演示漏洞利用，代码比较简单如下:\ntransaction.go 内容:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86  package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/spf13/cast\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) // 模拟数据存储 type user struct { id string money int } var userdata []*user func init() { userdata = append(userdata, \u0026amp;user{id: \u0026#34;Tom\u0026#34;, money: 10000}) userdata = append(userdata, \u0026amp;user{id: \u0026#34;John\u0026#34;, money: 10000}) userdata = append(userdata, \u0026amp;user{id: \u0026#34;hack\u0026#34;, money: 0}) } // 模拟交易系统API func main() { http.HandleFunc(\u0026#34;/transaction\u0026#34;, transactionHandler) http.ListenAndServe(\u0026#34;:1999\u0026#34;, nil) } // 假设这是交易处理器 func transactionHandler(w http.ResponseWriter, req *http.Request) { if req.URL.Path != \u0026#34;/transaction\u0026#34; { http.Error(w, \u0026#34;404 not found.\u0026#34;, http.StatusNotFound) return } switch req.Method { case \u0026#34;GET\u0026#34;: http.ServeFile(w, req, \u0026#34;form.html\u0026#34;) case \u0026#34;POST\u0026#34;: if err := req.ParseForm(); err != nil { fmt.Fprintf(w, \u0026#34;ParseForm() err: %v\u0026#34;, err) return } if e := transaction(req.FormValue(\u0026#34;Id\u0026#34;), req.FormValue(\u0026#34;toId\u0026#34;), req.FormValue(\u0026#34;money\u0026#34;)); e != nil { fmt.Fprintf(w,\u0026#34;%s\u0026#34;,e.Error()) return } fmt.Fprintf(w,\u0026#34;transaction successful.\u0026#34;) default: fmt.Fprintf(w, \u0026#34;Sorry, only GET and POST methods are supported.\u0026#34;) } } func transaction(Id, toId, money string) error { if len(Id) \u0026lt;= 0 || len(toId) \u0026lt;= 0 || cast.ToInt(money) \u0026lt;= 0 { return errors.New(\u0026#34;form invalid parameter\u0026#34;) } var user, recipient *user for _, u := range userdata { if u.id == Id { user = u break } } for _, r := range userdata { if r.id == toId { recipient = r break } } // 用户不存在 \tif user == nil || recipient == nil { return errors.New(\u0026#34;user does not exist\u0026#34;) } // 有钱才能转账 \tif user.money \u0026lt; 0 || user.money \u0026lt; cast.ToInt(money) { return errors.New(\u0026#34;your balance is insufficient\u0026#34;) } user.money = user.money - cast.ToInt(money) recipient.money = recipient.money + cast.ToInt(money) log.Printf(\u0026#34;用户 %s 向用户 %s 转账 %s 元.\u0026#34;, Id, toId, money) return nil }   我们把上面的代码跑起来，go run transaction.go\n[Running] go run \u0026quot;/Users/ding/Desktop/CSRF_Demo/transaction.go\u0026quot; 2021/03/12 21:50:08 Transaction Server Running.... 好了，服务器正常跑起来了，按照我们正常的系统流程是，我们登陆到了系统里面，系统里面有我们的浏览器会话数据，这时我们只想通过系统给出的交易接口操作就可以了，这里为了方便演示我使用postman进行测试。\n可以看到我们的交易系统设计的所需的参数，并且我们填写了请求表单数据，并且提交了这个请求。我们去服务器看看日志:\n[Running] go run \u0026quot;/Users/ding/Desktop/CSRF_Demo/transaction.go\u0026quot; 2021/03/12 21:50:08 Transaction Server Running.... 2021/03/12 21:54:41 用户 Tom 向用户 John 转账 2000 元. 可以看到有一条转账记录，说明我们操作成功了。\n   开始漏洞利用  按照正常人的思维我们就正常操作就行了，但是世界这么大怎么可能没有坏人呢？？？那下面把第一个服务器跑起来，并且访问第二个服务器看看结果怎么样？？\ncsrf.go文件里面内容:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main(){ http.HandleFunc(\u0026#34;/csrf\u0026#34;,csrfHandler) log.Println(\u0026#34;CSRF Server Running....\u0026#34;) http.ListenAndServe(\u0026#34;:2021\u0026#34;, nil) } func csrfHandler(writer http.ResponseWriter, request *http.Request) { http.ServeFile(writer, request, \u0026#34;csrf.html\u0026#34;) }   首先我把攻击利用服务器启动 go run csrf.go\n1  2021/03/12 22:16:43 CSRF Server Running....   然后我在同一浏览器里面访问这个地址http://127.0.0.1:2021/csrf。\n在你回车的那一秒，其实这个漏洞已经利用成功了。这个过程可能不是你直接在浏览器地址框直接输入，也可能是你在打开其他网站，其他网站里面有一个地址就是这个地址，或者是你在QQ或者一些聊天软件上，别人给你发送一个地址，在你点击那一秒这个攻击就成功了。\n那怎么证明成功了呢？我们去看看转账系统的日志。。\n可以看到有一条转账日志记录，这就是我们刚刚通过漏洞利用达成的转账效果。\n   那这个是怎么做到的呢？  通过我们攻击利用服务器上的代码可以看出来我们在服务器返回了一个csrf.html文件，那这个文件做了什么？？？\n文件内容如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;csrf 攻击演示\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;http://127.0.0.01:1999/transaction\u0026#34; method=POST\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;Id\u0026#34; value=\u0026#34;Tom\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;money\u0026#34; value=\u0026#34;5000\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;toId\u0026#34; value=\u0026#34;hack\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;script\u0026gt; document.forms[0].submit(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   相信是个程序员都能看懂我做了什么吧，不用细说。\n   CSRF攻击和防范  上面攻击过程就是我们常说的CSRF攻击，相比XSS，CSRF的名气似乎并不是那么大，很多人都认为CSRF“不那么有破坏性”，真的是这样吗？\nCSRF攻击的例子已经不是单个个例了，Gmail，Facebook，Twitter，YouTube这些都有个类似的漏洞事件。\n https://www.davidairey.com/google-gmail-security-hijack/   CSRF（Cross-site request forgery）跨站请求伪造：攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。\n 我刚才的例子就是一个典型的CSRF例子，受害者登录a.com，并保留了登录凭证（Cookie），攻击者引诱受害者访问了b.com，b.com 向 a.com 发送了一个请求：a.com/xx。浏览器会默认携带a.com的Cookie，a.com接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求，从而达到黑客的目的。\n   小 结  涉及到铭感数据操作的加强验证，客户端的数据不可信，服务器加强对数据校验，和加一些风控策略，例如验证码，手机短信，jwt，或者第三方验证码防火墙，也可以在请求的之前先拿到一个唯一的token，同源检测（Origin 和 Referer 验证），当然这些方法还不安全，如果有空会续更。\n","date":"Sep 16","permalink":"http://blog.ibyte.me/post/web-safe-csrf/","tags":null,"title":"Web Safe Csrf"},{"categories":null,"contents":"   概 述  大家都知道 session 是web应用在服务器端实现的一种用户和服务器之间认证的解决方案，目前 Go 标准包没有为 session 提供任何支持，本文我将讲解session的实现原理，和一些常见基于session安全产生的防御问题。\n当然有人可能看了会抬杠，说现在大部分不是前后端分离架构吗？对，你可以使用JWT解决你的问题。但是也有一些一体化web应用需要session，所以我准备造个轮子。自己造的轮子哪里出问题了，比别人更熟悉，有bug了，还不用求着别人修bug,自己修就好了，呵呵哈哈哈，当然这几句话有点皮😜。\n   需 求  我觉得一名好的程序员，在写程序之前应该列一下需求分析，整理一下思路，然后再去写代码。\n 支持内存存储会话数据 支持分布式redis会话存储 会话如果有心跳就自动续命30分钟（生命周期） 提供防御：中间人，会话劫持，会话重放等攻击     工作原理  首先必须了解工作原理才能写代码，这里我就稍微说一下，session是基于cookie实现的，一个session对应一个uuid也是sessionid，在服务器创建一个相关的数据结构，然后把这个sessionid通过cookie让浏览器保存着，下次浏览器请求过来了就会有sessionid，然后通过sessionid获取这个会话的数据。\n   代码实现  都是说着容易，实际写起来就是各种坑，不过我还是实现了。\n少说废话，还是直接干代码吧。\n 依赖关系  上面是设计的相关依赖关系图，session是一个独立的结构体， GlobalManager是整体的会话管理器负责数据持久化，过期会话垃圾回收工作♻️，storage是存储器接口，因为我们要实现两种方式存储会话数据或者以后要增加其他持久化存储，所以必须需要接口抽象支持，memory和redis是存储的具体实现。\nstorage接口  1 2 3 4 5 6 7 8 9  package sessionx // session storage interface type storage interface { Read(s *Session) error Create(s *Session) error Update(s *Session) error Remove(s *Session) error }   storage就9行代码，是具体的会话数据操作动作的抽象，全部参数使用的是session这个结构的指针，如果处理异常了就即错即返回。\n为什么把函数签名的形参使用指针类型的，这个我想看的懂人应该知道这是为什么了😁\nmemoryStore结构体  1 2 3  type memoryStore struct { sync.Map }   memoryStore结构体里面就嵌入sync.Map结构体，一开始是使用的map这种，但是后面发现在并发读写然后加sync.Mutex锁🔐，性能还不如直接使用sync.Map速度快。sync.Map用来做K:V存储的，也就是sessionid对应session data的。\n实现storage具体方法如下:\n1 2 3 4 5 6 7 8 9  func (m *memoryStore) Read(s *Session) error { if ele, ok := m.Load(s.ID); ok { // bug 这个不能直接 s = ele  s.Data = ele.(*Session).Data return nil } // s = nil  return fmt.Errorf(\u0026#34;id `%s` not exist session data\u0026#34;, s.ID) }   读取数据的时候先将持久化的数据读出来然后赋值给本次会话的session。\n注意: 在go的map中的struct中的字段不能够直接寻址，官方issue https://github.com/golang/go/issues/3117\n其他几个函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  func (m *memoryStore) Create(s *Session) error { m.Store(s.ID, s) return nil } func (m *memoryStore) Remove(s *Session) error { m.Delete(s.ID) return nil } func (m *memoryStore) Update(s *Session) error { if ele, ok := m.Load(s.ID); ok { // 为什么是交换data 因为我们不确定上层是否扩容换了地址  ele.(*Session).Data = s.Data ele.(*Session).Expires = s.Expires //m.sessions[s.ID] = ele  return nil } return fmt.Errorf(\u0026#34;id `%s` updated session fail\u0026#34;, s.ID) }   这句话代码没有什么好说的，写过go都能看得懂。\n垃圾回收:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  func (m *memoryStore) gc() { // recycle your trash every 10 minutes  for { time.Sleep(time.Minute * 10) m.Range(func(key, value interface{}) bool { if time.Now().UnixNano() \u0026gt;= value.(*Session).Expires.UnixNano() { m.Delete(key) } return true }) runtime.GC() // log.Println(\u0026#34;gc running...\u0026#34;)  } }   比较会话过期时间，过期就删除会话，以上就是内存存储的实现。\nredisStore结构体  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  type redisStore struct { sync.Mutex sessions *redis.Client } func (rs *redisStore) Read(s *Session) error { sid := fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, mgr.cfg.RedisKeyPrefix, s.ID) bytes, err := rs.sessions.Get(ctx, sid).Bytes() if err != nil { return err } if err := rs.sessions.Expire(ctx, sid, mgr.cfg.TimeOut).Err(); err != nil { return err } if err := decoder(bytes, s); err != nil { return err } // log.Println(\u0026#34;redis read:\u0026#34;, s)  return nil } func (rs *redisStore) Create(s *Session) error { return rs.setValue(s) } func (rs *redisStore) Update(s *Session) error { return rs.setValue(s) } func (rs *redisStore) Remove(s *Session) error { return rs.sessions.Del(ctx, fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, mgr.cfg.RedisKeyPrefix, s.ID)).Err() } func (rs *redisStore) setValue(s *Session) error { bytes, err := encoder(s) if err != nil { return err } err = rs.sessions.Set(ctx, fmt.Sprintf(\u0026#34;%s:%s\u0026#34;, mgr.cfg.RedisKeyPrefix, s.ID), bytes, mgr.cfg.TimeOut).Err() return err }   代码也就50行左右，很简单就是通过redis客户端对数据进行持久化操作，把本地的会话数据提供encoding/gob序列化成二进制写到redis服务器上存储，需要的时候再反序列化出来。\n那么问题来了，会有人问了，redis没有并发问题吗？\n👨‍💻‍： 那我肯定会回答，你在问这个问题之前我不知道你有没有了解过redis？？？\nRedis 并发竞争指的是多个 Redis 客户端同时 set key 引起的并发问题，Redis 是一种单线程机制的 NoSQL 数据库，所以 Redis 本身并没有锁的概念。\n但是多客户端同时并发写同一个 key，一个 key 的值是 1，本来按顺序修改为 2,3,4 ，最后 key 值是 4，但是因为并发去写 key，顺序可能就变成了 4,3,2，最后 key 值就变成了 2。\n我这个库当前也就一个客户端，如果你部署到多个机子，那就使用 setnx(key, value) 来实现分布式锁，我当前写的这个库没有提供分布式锁，具体请自行google。\nmanager结构体  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  type storeType uint8 const ( // memoryStore store type  M storeType = iota // redis store type  R SessionKey = \u0026#34;session-id\u0026#34; ) // manager for session manager type manager struct { cfg *Configs store storage } func New(t storeType, cfg *Configs) { switch t { case M: // init memory storage  m := new(memoryStore) go m.gc() mgr = \u0026amp;manager{cfg: cfg, store: m} case R: // parameter verify  validate := validator.New() if err := validate.Struct(cfg); err != nil { panic(err.Error()) } // init redis storage  r := new(redisStore) r.sessions = redis.NewClient(\u0026amp;redis.Options{ Addr: cfg.RedisAddr, Password: cfg.RedisPassword, // no password set  DB: cfg.RedisDB, // use default DB  PoolSize: int(cfg.PoolSize), // connection pool size  }) // test connection  timeout, cancelFunc := context.WithTimeout(context.Background(), 8*time.Second) defer cancelFunc() if err := r.sessions.Ping(timeout).Err(); err != nil { panic(err.Error()) } mgr = \u0026amp;manager{cfg: cfg, store: r} default: panic(\u0026#34;not implement store type\u0026#34;) } }   manager结构体也就两个字段，一个存放我们全局配置信息，一个我们实例化不同的持久化存储的存储器，其他代码就是辅助性的代码，不细说了。\nSession结构体  这个结构体是对应着浏览器会话的结构体，设计原则是一个id对应一个session结构体。\n1 2 3 4 5 6 7 8 9 10 11  type Session struct { // 会话ID  ID string // session超时时间  Expires time.Time // 存储数据的map  Data map[interface{}]interface{} _w http.ResponseWriter // 每个session对应一个cookie  Cookie *http.Cookie }   具体操作函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  // Get Retrieves the stored element data from the session via the key func (s *Session) Get(key interface{}) (interface{}, error) { err := mgr.store.Read(s) if err != nil { return nil, err } s.refreshCookie() if ele, ok := s.Data[key]; ok { return ele, nil } return nil, fmt.Errorf(\u0026#34;key \u0026#39;%s\u0026#39; does not exist\u0026#34;, key) } // Set Stores information in the session func (s *Session) Set(key, v interface{}) error { lock[\u0026#34;W\u0026#34;](func() { if s.Data == nil { s.Data = make(map[interface{}]interface{}, 8) } s.Data[key] = v }) s.refreshCookie() return mgr.store.Update(s) } // Remove an element stored in the session func (s *Session) Remove(key interface{}) error { s.refreshCookie() lock[\u0026#34;R\u0026#34;](func() { delete(s.Data, key) }) return mgr.store.Update(s) } // Clean up all data for this session func (s *Session) Clean() error { s.refreshCookie() return mgr.store.Remove(s) } // 刷新cookie 会话只要有操作就重置会话生命周期 func (s *Session) refreshCookie() { s.Expires = time.Now().Add(mgr.cfg.TimeOut) s.Cookie.Expires = s.Expires // 这里不是使用指针  // 因为这里我们支持redis 如果web服务器重启了  // 那么session数据在内存里清空  // 从redis读取的\u0008数据反序列化地址和重新启动的不一样  // 所有直接数据拷贝  http.SetCookie(s._w, s.Cookie) }   上面是几个函数是，会话的数据操作函数，refreshCookie()是用来刷新浏览器cookie信息的，因为我在设计的时候只有浏览器有心跳也就是有操作数据的时候，管理器就默认为这个浏览器会话还是活着的，会自动同步更新cookie过期时间，这个更新过程可不是光刷新cookie就完事的了，持久化的话的数据过期时间也一样更新了。\nHandler方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  // Handler Get session data from the Request func Handler(w http.ResponseWriter, req *http.Request) *Session { // 从请求里面取session  var session Session session._w = w cookie, err := req.Cookie(mgr.cfg.Cookie.Name) if err != nil || cookie == nil || len(cookie.Value) \u0026lt;= 0 { return createSession(w, cookie, \u0026amp;session) } // ID通过编码之后长度是73位  if len(cookie.Value) \u0026gt;= 73 { session.ID = cookie.Value if mgr.store.Read(\u0026amp;session) != nil { return createSession(w, cookie, \u0026amp;session) } // 防止web服务器重启之后redis会话数据还在  // 但是浏览器cookie没有更新  // 重新刷新cookie  // 存在指针一致问题，这样操作还是一块内存，所有我们需要复制副本  _ = session.copy(mgr.cfg.Cookie) session.Cookie.Value = session.ID session.Cookie.Expires = session.Expires http.SetCookie(w, session.Cookie) } // 地址一样不行！！！  // log.Printf(\u0026#34;mgr.cfg.Cookie pointer:%p \\n\u0026#34;, mgr.cfg.Cookie)  // log.Printf(\u0026#34;session.cookie pointer:%p \\n\u0026#34;, session.Cookie)  return \u0026amp;session } func createSession(w http.ResponseWriter, cookie *http.Cookie, session *Session) *Session { // init session parameter  session.ID = generateUUID() session.Expires = time.Now().Add(mgr.cfg.TimeOut) _ = mgr.store.Create(session) // 重置配置cookie模板  session.copy(mgr.cfg.Cookie) session.Cookie.Value = session.ID session.Cookie.Expires = session.Expires http.SetCookie(w, session.Cookie) return session }   Handler函数是从http请求里面读取到sessionid然后从持久化层读取数据然后实例化一个session结构体的函数，没有啥好说的，注释写上面了。\n   安全防御问题  首先我还是那句话：不懂攻击，怎么做防守。 那我们先说说这个问题怎么产生的:\n 中间人攻击（Man-in-the-MiddleAttack，简称MITM攻击）是一种间接的入侵攻击，这种攻击模式是通过各种技术手段将受入侵者控制的一台计算机虚拟放置在网络连接中的两台通信计算机之间，这台计算机就称为中间人。\n 这个过程，正常用户在通过浏览器访问我们编写的网站，但是这个时候有个hack通过arp欺骗，把路由器的流量劫持到他的电脑上，然后黑客通过一些特殊的软件抓包你的网络请求流量信息，在这个过程中如果你sessionid如果存放在cookie中，很有可能被黑客提取处理，如果你这个时候登录了网站，这是黑客就拿到你的登录凭证，然后在登录进行重放也就是使用你的sessionid，从而达到访问你账户相关的数据目的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  func (s *Session) MigrateSession() error { // 迁移到新内存 防止会话一致引发安全问题  // 这个问题的根源在 sessionid 不变，如果用户在未登录时拿到的是一个 sessionid，登录之后服务端给用户重新换一个 sessionid，就可以防止会话固定攻击了。  s.ID = generateUUID() newSession, err := deepcopy.Anything(s) if err != nil { return errors.New(\u0026#34;migrate session make a deep copy from src into dst failed\u0026#34;) } newSession.(*Session).ID = s.ID newSession.(*Session).Cookie.Value = s.ID newSession.(*Session).Expires = time.Now().Add(mgr.cfg.TimeOut) newSession.(*Session)._w = s._w newSession.(*Session).refreshCookie() // 新内存开始持久化  // log.Printf(\u0026#34;old session pointer:%p \\n\u0026#34;, s)  // log.Printf(\u0026#34;new session pointer:%p \\n\u0026#34;, newSession.(*Session))  //log.Println(\u0026#34;MigrateSession:\u0026#34;, newSession.(*Session))  return mgr.store.Create(newSession.(*Session)) }   如果大家写过Java语言，都应该使用过springboot这个框架，如果你看过源代码，那就知道这个框架里面的session安全策略有一个migrateSession选项，表示在登录成功之后，创建一个新的会话，然后讲旧的 session 中的信息复制到新的 session 中。\n我参照他的策略，也同样在我这个库里面实现了，在用户匿名访问的时候是一个 sessionid，当用户成功登录之后，又是另外一个 sessionid，这样就可以有效避免会话固定攻击。\n使用的时候也可以随时使用通过MigrateSession进行调用，这个函数一但被调用，原始数据和id全部被刷新了，内存地址也换了，可以看我的源代码。\n   使用演示  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; sessionx \u0026#34;github.com/higker/sesssionx\u0026#34; ) var ( // 配置信息  cfg = \u0026amp;sessionx.Configs{ TimeOut: time.Minute * 30, RedisAddr: \u0026#34;127.0.0.1:6379\u0026#34;, RedisDB: 0, RedisPassword: \u0026#34;redis.nosql\u0026#34;, RedisKeyPrefix: sessionx.SessionKey, PoolSize: 100, Cookie: \u0026amp;http.Cookie{ Name: sessionx.SessionKey, Path: \u0026#34;/\u0026#34;, Expires: time.Now().Add(time.Minute * 30), // TimeOut  Secure: false, HttpOnly: true, }, } ) func main() { // R表示redis存储 cfg是配置信息 \tsessionx.New(sessionx.R, cfg) http.HandleFunc(\u0026#34;/set\u0026#34;, func(writer http.ResponseWriter, request *http.Request) { session := sessionx.Handler(writer, request) session.Set(\u0026#34;K\u0026#34;, time.Now().Format(\u0026#34;2006 01-02 15:04:05\u0026#34;)) fmt.Fprintln(writer, \u0026#34;set time value succeed.\u0026#34;) }) http.HandleFunc(\u0026#34;/get\u0026#34;, func(writer http.ResponseWriter, request *http.Request) { session := sessionx.Handler(writer, request) v, err := session.Get(\u0026#34;K\u0026#34;) if err != nil { fmt.Fprintln(writer, err.Error()) return } fmt.Fprintln(writer, fmt.Sprintf(\u0026#34;The stored value is : %s\u0026#34;, v)) }) http.HandleFunc(\u0026#34;/migrate\u0026#34;, func(writer http.ResponseWriter, request *http.Request) { session := sessionx.Handler(writer, request) err := session.MigrateSession() if err != nil { log.Println(err) } fmt.Fprintln(writer, session) }) _ = http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) }      小 结  推荐还是使用JWT这种方式做鉴权，不过也有一体化web应用的session也不会被这么早淘汰，如果上面有问题，欢迎大佬们pr，还有部分代码没有列出，可以去仓库看看。\n   相关链接  代码仓库：https://github.com/auula/sessionx\n","date":"Sep 16","permalink":"http://blog.ibyte.me/post/golang-web-session-implement/","tags":null,"title":"Golang Web Session Implement"},{"categories":null,"contents":"   前 言  谈到分布式应用那必然离不开分布式锁🔐的问题，分布式锁在分布式应用中应用广泛，本文就讲讲基于redis实现的分布式锁的一些问题。\n   锁  可能各位coder接触最多的还是在多线程的环境下，为了保证一个代码块在同一时间只能由一个线程访问情况，例如下图：\n对于单进程的并发场景，可以使用编程语言及相应的类库提供的锁，如Java中的 synchronized 语法以及 ReentrantLock，Golang中的sync包下面的mutex，Rust中的async_std::sync::Mutex，避免并发问题，这实际上是本地锁的方式。\n   分布式锁  但是现在流行的分布式架构，在分布式环境下，如何保证不同节点的线程同步执行呢？或者共享资源怎么上锁呢？？？\n在将应用拆分为分布式应用之前的单机系统中，对一些并发场景读取公共资源时如扣库存，卖车票之类的需求可以简单的使用同步或者是加锁就可以实现，但是应用分布式了之后系统由以前的单进程多线程的程序变为了多进程多线程，这时使用以上的解决方案明显就不够了。\n一般业界有几种解决方:\n 基于 DB 的唯一索引 基于 Memcached的 add 命令 基于 Zookeeper 的临时有序节点 基于 Redis 的NX EX 基于Chubby粗粒度分布式锁服务     Redis的坑你填了几个？   如果在分布式场景中，实现不同客户端的线程对代码和资源的同步访问，保证在多线程下处理共享数据的安全性，就需要用到分布式锁技术，我就来写写基于Redis的一些坑😁。\n 在分布式时，在程序中修改已有数据时，需要先读取，然后进行修改保存，此时很容易遇到并发问题。由于修改和保存不是原子操作，在并发场景下，部分对数据的操作可能会丢失，本地锁无法在多个服务器之间生效，这时候保证数据的一致性就需要分布式锁来实现。\nRedis 锁主要利用 Redis 的 setnx 命令实现，\n 加锁命令：SETNX key value，当键不存在时，对键进行设置操作并返回成功，否则返回失败,KEY 是锁的唯一标识，一般按业务来决定命名。 解锁命令：DEL key，通过删除键值对释放锁，以便其他线程可以通过 SETNX 命令来获取锁。 锁超时：EXPIRE key timeout, 设置 key 的超时时间，以保证即使锁没有被显式释放，锁也可以在一定时间后自动释放，避免资源被永远锁住。  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  // 伪代码实现 fn main(){letkey: \u0026amp;\u0026#39;static str =\u0026#34;sync_lock\u0026#34;;ifup_lock(key,1)==1{// 设置超时 expire(key,30)// .....业务逻辑 }}// 基于redis SETNX 和 EXPIRE 的实现，问题代码 fn up_lock(key: \u0026amp;\u0026#39;static str,num: i8)-\u0026gt; i8 {// ..... 上锁逻辑 return1;}fn expire(key: \u0026amp;\u0026#39;static str,num: i8){// ... 自定义超时 }  写完这么一看还没有什么问题，其实上面🕳坑大着呢！！！如果你是这么去实现的，那笔者恭喜你，你掉坑里了😜（PS:这里不是代码问题导致的，而是SETNX 和 EXPIRE 非原子性导致的）。\n  SETNX 和 EXPIRE 非原子性  如果 SETNX 成功，在设置锁超时时间后，服务器挂掉、重启或网络问题等，导致 EXPIRE 命令没有执行，锁没有设置超时时间变成死锁。\n 锁误解除  如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程A实际释放的线程是 B 加的锁，从而导致锁混乱，然后导致实际逻辑代码混乱和乃至关键数据丢失。\n 超时解锁导致并发  如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行，那就没有分布式锁存在的意义了🤷‍。\n 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。   不可重入  当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的，如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。\n   小 结  Redis是个高性能的中间件，但是如果用在分布式锁上实现依然存在问题，我在一些网络文章看到很多人大部分都是用redis来解决分布式锁问题，希望这篇文章能帮助到你，记得点个关注！！\n","date":"Sep 16","permalink":"http://blog.ibyte.me/post/redis-distributed-lock/","tags":null,"title":"Redis Distributed Lock"},{"categories":null,"contents":"   👨‍💻‍：直奔话题 HotRing，少说废话。   去年阿里的Tair团队发表过一篇论文HotRing: A Hotspot-Aware In-Memory Key-Value Store，这篇论文里面讲述了阿里的最快的KV分布式存储引擎核心HotRing的技术与实现，我看了他们的数据显示其引擎吞吐性能可达600M ops/s，这个速度比传统的KVS系统2.58倍的性能提升，于是我就抱着好奇去看看了那篇论文然后就有这篇文章。\n    👨‍💻‍： 有问题就有故事？  一个新东西或者技术出现，那就说明老的那套方案技术存在某种缺陷或者满足不了某种的特殊需求了\u0026hellip;\u0026hellip;\n问题动机就是：某一时刻流量上来了，系统扛不住了\u0026hellip; 只要说到高并发，相信这个回答占大多数。HotRing的出现也是这个原因，真的是面向问题编程😜。。。挖槽，真的验证这句话了。。。\n这张图就是传统的kvs架构图，不管你中间的那一层用什么，在某些时刻，缓存系统迎来巨大的访问量（双11秒杀），可能存在访问倾斜(什么？你问我什么是访问倾斜，好吧你不适合编程。😜)，大多数访问集中在极少数数据上（例如微博热点事件）。\n对于集群级别的热点监测倍受重视，如一致性 Hash，某个节点上的数据被读写访问次数远远高出其他节点，对此类行为没有很好的监测到。\n还有单机热问题上没有优化，例如计算机内存的KV存储热点和查询速度没有优化。\n一个好的存储这些事情都是必须去做的，从上到下，从下到上，每层都在解决一部分问题，总和就是一个大的问题，如果你不能把问题拆成小问题，那你那个问题不一定能解决的好，例如CPU Cache、LevelDB的设计。\n   👨‍💻‍：HotRing 干了什么？？？  现有技术，内存 KVS 对时延要求是很高的，一个在并发中无锁的数据结构尤为重要，然后就是一个能让热点数据能自我跑到最容易访问的地方提高读取速度的。\n 热点是动态变化的，如何检测，如何转移?  这个问题是逃不开的，在HotRing的设计，论文中提到了一个概念就是有序环。\n它做了什么？看得懂上图就能看出来，他把传统的Map的底层的存储链表+数组结构换成了一个环形链结构，然后通过head自由的控制指向哪一个节点。\n传统的结构可能你的数据在最后一层或者数据非常多，程序只能通过head顺序查找，时间复杂度O(n)\n而环形的结构，避免多次遍历希望把热点数据放在冲突链前面，传统的则需要不断修改节点，需要不断移动节点，必须从头节点开始，到尾节点终止。移动头指针的情况下，会导致一些节点无法被访问。\n移动热点不方便，需要把中间节点移动到头节点去，移动链表中的节点很复杂且难以做到无锁并发，就上图这个操作就要3步。\n改成环链，Head可以指向任意节点，即从任意节点开始遍历，然后还能对数据进行排序。\n为什么有序???  这个就属于环链的特点了，没有终结点，如果查找值不存在，无法判断何时终结。改成有序的了，可以根据前后项的关系判断是否终结本次查询。\n 前驱节点 \u0026lt; 待查找节点 \u0026lt;后驱节点 miss 前驱节点 \u0026gt; 后驱节点 \u0026amp;\u0026amp; 待查找节点 \u0026lt; 后驱节点 miss 前驱节点 \u0026gt; 后驱节点 \u0026amp;\u0026amp; 待查找节点 \u0026gt; 前驱节点 miss 待查找节点 == 节点 K hit  排序的过程就是利用key排序可以解决这个问题，若目标key介于连续两个item的key之间，说明为read miss操作，即可终止返回。由于实际系统中，数据key的大小通常为10~100B，比较会带来巨大的开销。哈希结构利用tag来减少key的比较开销。\ntag是哈希值的一部分，每个key计算的哈希值，前k位用来哈希表的定位，后n-k位作为冲突链中进一步区分key的标志。为了减小排序开销，我们构建字典序：order = (tag, key)，先根据tag进行排序，tag相同再根据key进行排序。\n有了这些条件，HotRing就是可控的了。\n   🔥：热点数据跟踪  由于在不同的时间里，热点数据都是不停变化的，可能t1-t2这个时间段热的数据可能是在n1节点上，在t段数据后有发生了变化在n2节点上。\n热点识别转移有两种策略：\n  随机移动策略，效率高、效果可能差（不需要采样、计算，响应速度快），例如第R次访问如果是 Hot Access，保持不变，如果是 Cold Access，移动头指针指向冷数据，在热点集中时非常有效，头指针会趋向于指向热点数据，否则可能会频繁摇摆。\n  统计采样策略，效率低、效果可能更好，索引格式有特殊要求如下图：\n   针对RCU更新操作的采样优化 热点继承防止冷启动 采样分析策略如何选出最优位置  内存指针分配64bits，address 实际使用了48bits，采样所需的元数据结构上面的图所示，分别在头指针处设置Total Counter，记录该环的访问总次数，每个item设置Counter记录该item的访问次数。因为内存指针需要分配64bits，但实际系统地址索引只使用其中的48bits。我们使用剩余16bits设置标志位(例如Total Counter、Counter等)，保证不会增加额外的元数据开销。该策略的优势是，通过采样分析，可以计算选出最优的头指针位置，稳态时性能表现更优。\n数据采样\n我来解释一下公式，k= 有多少个节点，ni= 当前节点访问频率，N总的访问次数，mod计算出来的内存指针需要移动次数，然后就是概率*访问的成本，然后累加就知道访问得到热点数据的成本，最后就是t就是指针调整到的节点。\n为什么不是直接转移到 max(ni)?\n这个问题显然就是如果你直接调整到热节点位置，那么这个环路上不只是有一个热点数据节点，所有需要使用采用经过公式计算之后的。\n 写入密集型的热点：RCU Read读热点、Update写入密集型热点 Less Than 8Bytes -- CAS More Than 8Bytes -- RCU 如果头指针指向的节点被 Update，给前驱节点 Counter + 1     🔐：无锁并发访问  Tair的RCU无锁引擎是HotRing的设计基础，因为没有对环形链表结构修改，所以不存在并发问题，可以直接不加锁访问。\n但是在并发插入时数据丢失问题，解决办法就是使用了CompareAndSwap，保证同时只有一个线程能够修改成功。\n什么是CompareAndSwap? 通常会记录下某块内存中的旧值，通过对旧值进行一系列的操作后得到新值，然后通过CAS操作将新值与旧值进行交换。如果这块内存的值在这期间内没被修改过，则旧值会与内存中的数据相同，这时CAS操作将会成功执行 使内存中的数据变为新值。\nUpdate 和 Insertion 并发引发的数据丢失，怎么看这个图，假设B为热点数据，程序每次找的B必须经过A，因为A在环路上是在B前面，那么访问B多少次A就是多少次，那么这个不是理想的，那就让hard指针指向A让B之间没有其他的值。\n在链A-\u0026gt;B-\u0026gt;D上，线程1进行插入C的操作，同时线程2进行RCU更新B的操作，尝试更新为B'。线程1修改B的指针指向C，完成插入。而线程2修改A的指针指向B\u0026lsquo;完成更新。两个线程并发修改不同的内存，均可成功返回。但是这时遍历整条链(A-\u0026gt;B'-\u0026gt;D)，将发现C无法被遍历到，导致正确性问题。当线程2更新B时，首先需要将B的Occupied标志位置位。线程1插入C需要修改B的指针(Next Item Address)，若发现Occupied标志位已置位，则需要重新遍历链表，尝试插入，通过使并发操作竞争修改同一内存地址，保证并发操作的正确性，利用相同原理保证了头指针移动操作，与CRUD操作的并发正确性，因此实现了HotRing的无锁并发访问。\n更多细节自己去看论文吧，上面部分总结。\n   论文资料   https://www.usenix.org/system/files/fast20-chen_jiqiang.pdf  ","date":"Sep 16","permalink":"http://blog.ibyte.me/post/alibaba-hot-ring/","tags":null,"title":"Alibaba Hot Ring Perceive"},{"categories":null,"contents":"   概 述   好久没有更新rust相关的内容了，更新一波Rust的内容，本篇讲介绍一下Rust中的复合数据类型。\n    Composite Type  复合数据类型是一种数据类型，它可以原始的基本数据类型和其它的复合类型所构成， 构成一个复合类型的动作，又称作组合。\n本文讲介绍一下在Rust中有tuple、array、struct、enum几个复合类型。\n   tuple  tuple即元组，元组类型是由多个不同类型的元素组成的复合类型，通过()小括号把元素组织在一起成一个新的数据类型。元组的长度在定义的时候就已经是固定的了，不能修改，如果指定了元素的数据类型，那么你的元素就要对号入座！！！否则编译器会教训你！\n例子：\n1 2 3 4 5 6 7 8 9 10 11  fn main(){// 指定数据类型 lettup_type:(i8,i32,bool)=(21,-1024,true);// 解构元素 let(one,two,three)=tup_type;// 二维的元组 lettup_2d:(f64,(i8,i32,bool))=(3.1415927,(one,two,three));println!(\u0026#34;tup_2d = {:?}\u0026#34;,tup_2d);// 索引 println!(\u0026#34;π = {:?}\u0026#34;,tup_2d.0);}  元组的访问方式有好几种，通过下标去访问，也可以使用解构赋值给新的变量去访问，但是不支持迭代器去访问。\n1 2 3  forvintup_2d.1.iter(){println!(\u0026#34;{}\u0026#34;,v)}  1 2 3 4 5 6 7 8 9 10 11 12 13  Compiling playground v0.0.1 (/playground) error[E0599]: no method named `iter` found for tuple `(i8, i32, bool)` in the current scope --\u0026gt; src/main.rs:10:23 | 10 | for v in tup_type.iter() { | ^^^^ method not found in `(i8, i32, bool)` error: aborting due to previous error For more information about this error, try `rustc --explain E0599`. error: could not compile `playground` To learn more, run the command again with --verbose.   元组的每个元素的类型可以不同，因此您无法对其进行迭代。元组甚至不能保证以与类型定义相同的顺序存储数据，因此即使您自己为它们实现Iterator，它们也不适合进行有效的迭代。\n但是如果元素是支持实现了Iterator就可以通过.iter()进行迭代访问。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  letmutarrays:[usize;5]=[0;5];foriin0..5{arrays[i]=i+1;}println!(\u0026#34;{:?}\u0026#34;,arrays);lettup_arr:(\u0026amp;str,[usize;5])=(\u0026#34;tup_arr\u0026#34;,arrays);println!(\u0026#34;{:?}\u0026#34;,tup_arr);forvintup_arr.1.iter(){println!(\u0026#34;{}\u0026#34;,v)}  例如上的元素是一个array，Rust中的数组和其他语言一样，一组类型相同的元素组成的复合类型，数组在底层存储是一块连续的内存空间。\n   array  Rust中的数组声明是[T;n]进行的，T是元素类型，n是这组元素有多少个坑位，创建的时候可以去掉类型和大小，程序会自动推断出来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // 数组 letarr:[f32;3]=[1.0,2.2,3.33];println!(\u0026#34;{:?}\u0026#34;,arr);// 类型自动推导 letarr_infer=[\u0026#34;Hello\u0026#34;,\u0026#34;,\u0026#34;,\u0026#34;World!\u0026#34;];letmutstr=String::new();// 迭代器 forvinarr_infer.iter(){str.push_str(v);}println!(\u0026#34;str = {}\u0026#34;,str);  点击查看元组代码案例\n   enum  枚举类型，如果你之前从事过Java相关的开发应该不陌生，在Rust里面也有枚举类型，枚举类型是一个自定义数据类型，通过enum关键字来声明，body里面可以包含多个自定义的枚举值，枚举可以用来限制某个值或者类型范围。\n1 2 3 4 5  #[derive(Debug)]enum Gender{Boy,Girl,}  上面就定义一了个类型名字为Gender的枚举，Boy和Girl是枚举可供使用的值，#[derive(Debug)]注释是让Gender自动实现Debug tarit后面文章将深入。\n   struct  结构体可以把一些自定义的数据类型通过已有的类型组装成一个新的自定义数据类型，通过struct关键字就可以创建一个结构体，结构体字段格式name:type，name是结构体字段名，type是字段的类型，默认是不可变的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  fn main(){// 枚举现在取值范围 #[derive(Debug)]enum Gender{Boy,Girl,}// 定义一个结构体 #[derive(Debug)]struct Programmer\u0026lt;\u0026#39;skill\u0026gt;{name: String,skill: [\u0026amp;\u0026#39;skillstr;3],sex: Gender,}// 创建一个实例 letengineer=Programmer{name: String::from(\u0026#34;Jaco Ding\u0026#34;),// String类型内容可变 skill: [\u0026#34;Java\u0026#34;,\u0026#34;Go\u0026#34;,\u0026#34;Rust\u0026#34;],// 一个长度为3的字符串面量类型的数组 sex:Gender::Boy,// 通过枚举限制参数类型 };println!(\u0026#34;engineer = {:?}\u0026#34;,engineer);}  有了自定义的类型了也就是struct就可以通过自定义的类型来处理一些特殊的需求了，例如下面的代码定义了一个元素类型为Programmer长度为2的数组。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  letDoris=Programmer{name: String::from(\u0026#34;Doris\u0026#34;),skill: [\u0026#34;Vue\u0026#34;,\u0026#34;TypeScript\u0026#34;,\u0026#34;JavaScript\u0026#34;],sex:Gender::Girl,};letJaco=Programmer{name: String::from(\u0026#34;Jaco\u0026#34;),skill: [\u0026#34;Java\u0026#34;,\u0026#34;Go\u0026#34;,\u0026#34;Rust\u0026#34;],sex:Gender::Boy,};letemployees:[Programmer;2]=[Doris,Jaco];foreinemployees.iter(){println!(\u0026#34;{:?}\u0026#34;,e)}  结构体Programmer上的\u0026lt;'skill\u0026gt; 解决skill数组的生命周期问题undeclared lifetime，所有权问题，所有权是Rust语言核心的知识点，这些在后面文章中慢慢更新。\n   小结  Rust中的结构体还有两种特殊结构：元组结构体、单结构体，枚举也有带有参数的枚举。。。本文就学习总结了一下常见复合类型的使用，未深入。\n","date":"Sep 16","permalink":"http://blog.ibyte.me/post/compound-data-type-of-rust/","tags":null,"title":"Compound Data Type of Rust"},{"categories":null,"contents":"   前言   断断续续看了半个月的Rust书，学了点基础，不知道做什么好？？于是我想着用业余时间撸一个command line application的骨架。然后就有了https://github.com/auula/falsework这个项目，falsework可以帮助你快速构建一个命令行应用。这篇文章写写falsework的使用并在后部分介绍一下怎么实现的。\n 看了看这张图，那我估计还在坡道起步。。\n   导入依赖   https://crates.io/crates/falsework  在你的项目中添加依赖如下：\n1 2  [dependencies] falsework = \u0026#34;0.1.3\u0026#34;      快速构建  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  usestd::error::Error;usefalsework::{app,cmd};fn main(){// 通过falsework创建一个骨架 letmutapp=falsework::app::new();// 应用元数据信息 app.name(\u0026#34;calculator\u0026#34;).author(\u0026#34;Leon Ding \u0026lt;ding@ibyte.me\u0026gt;\u0026#34;).version(\u0026#34;0.0.1\u0026#34;).description(\u0026#34;A calculator that only supports addition.\u0026#34;);// 构建命令行项 letmutcommand=cmd::CommandItem{// run 命令所对应命令行逻辑代码 run: |ctx|-\u0026gt; Result\u0026lt;(),Box\u0026lt;dynError\u0026gt;\u0026gt;{// 通过上下文获取flag绑定的数据 letx=ctx.value_of(\u0026#34;--x\u0026#34;).parse::\u0026lt;i32\u0026gt;().unwrap();lety=ctx.value_of(\u0026#34;--y\u0026#34;).parse::\u0026lt;i32\u0026gt;().unwrap();println!(\u0026#34;{} + {} = {}\u0026#34;,x,y,x+y);// 如果处理发生了错误则调用 cmd::err_msg 会优雅的退出 // Err(cmd::err_msg(\u0026#34;Application produce error！\u0026#34;)); Ok(())},// 命令帮助信息 long: \u0026#34;这是一个加法计算程序需要两个flag参数 --x --y\u0026#34;,// 命令介绍 short: \u0026#34;加法计算\u0026#34;,// 通过add激活命令 r#use: \u0026#34;add\u0026#34;,}.build();// 给add命令绑定flag command.bound_flag(\u0026#34;--x\u0026#34;,\u0026#34;加数\u0026#34;);command.bound_flag(\u0026#34;--y\u0026#34;,\u0026#34;被加数\u0026#34;);// 往app里面添加一个命令集 app.add_cmd(command);// 最后run 程序开始监听命令行输入 app.run();}  上面这个例子运行起来结果:\n1 2  $: ./calculator add --x=10 --y=10 10 + 10 = 20   到此为止你就快速构建一个命令行计算器了，你只需要写你核心逻辑，其他操作falsework帮助你完成。\n 例如如果我不记得了命令了，只记得一个单词或者字母，程序会帮助你修复：  1 2 3 4 5  $: ./calculator a You need this command ? add a : The corresponding command set was not found!   可以看到程序提示你有一个对应的add命令可以使用，如果不知道add有啥参数，在后面 加上--help即可获得帮助信息：  1 2 3 4 5 6 7 8 9 10 11  $: ./calculator add --help Help: 这是一个加法计算程序需要两个flag参数 --x --y Usage: calculator add [flags] Flags: --y, 被加数 --x, 加数   构建出来主程序预览：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  $: ./calculator A calculator that only supports addition. calculator 0.0.1 Leon Ding \u0026lt;ding@ibyte.me\u0026gt; Usage: calculator [command] Available Commands: add\t加法计算 Flags: --help help for calculator Use \u0026#34;calculator [command] --help\u0026#34; for more information about a command.      其他操作  有多种构建方式，例如下面的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  #[test]fn test_add_commands(){letmutapp=falsework::app::new();app.name(\u0026#34;calculator\u0026#34;).author(\u0026#34;Leon Ding \u0026lt;ding@ibyte.me\u0026gt;\u0026#34;).version(\u0026#34;0.0.2\u0026#34;).description(\u0026#34;A command line program built with Falsework.\u0026#34;);letcommand_list=vec![cmd::CommandItem{run: |_ctx|-\u0026gt; Result\u0026lt;(),Box\u0026lt;dynError\u0026gt;\u0026gt;{// _ctx.args 获取命令行参数 println!(\u0026#34;call foo command.\u0026#34;);Ok(())},long: \u0026#34;这是一个测试命令，使用foo将调用foo命令。\u0026#34;,short: \u0026#34;foo命令\u0026#34;,r#use: \u0026#34;foo\u0026#34;,},cmd::CommandItem{run: |_ctx|-\u0026gt; Result\u0026lt;(),Box\u0026lt;dynError\u0026gt;\u0026gt;{println!(\u0026#34;call bar command.\u0026#34;);Ok(())},long: \u0026#34;这是一个测试命令，使用bar将调用bar命令。\u0026#34;,short: \u0026#34;bar命令\u0026#34;,r#use: \u0026#34;bar\u0026#34;,},].iter().map(|c|c.build()).collect();app.commands(command_list);println!(\u0026#34;{:#?}\u0026#34;,app);}     Falsework的设计  整体来说也就是3大块，对应一个cli程序抽象的话也就这么多了，然后就是对单块的结构进行封装如图，然后就是构建一个骨架了。\n拿上面这个例子来说，在你敲击回车那一刻，骨架要帮做很多args解析的事情，然后构建对应任务处理。\n这张图就是当程序监听到命令行有输入操作的时候要做的事情，我把他抽象画成了一个图，大部分程序员应该能看得懂，看不懂可以对照仓库代码看看，虽然代码写的一坨，很low代码，毕竟还只是刚刚入坑Rust。。。。新手朋友可以看看，对了有启发或者帮助记得留一个star！\n   仓库   https://github.com/auula/falsework  ","date":"Sep 16","permalink":"http://blog.ibyte.me/post/rust-falsework-desgin/","tags":null,"title":"Rust Falsework Desgin"},{"categories":null,"contents":"相信大家在开发的过程中经常会使用到go中并发利器channel，channel 是CSP并发模型中最重要的一个组件，两个独立的并发实体通过共享的通讯channel进行通信。大多数人只是会用这么个结构很少有人讨论它底层实现，这篇文章讲写写channel的底层实现。\n   channel  channel的底层实现是一个结构体，源代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  type hchan struct { qcount uint // total data in the queue  dataqsiz uint // size of the circular queue  buf unsafe.Pointer // points to an array of dataqsiz elements  elemsize uint16 closed uint32 elemtype *_type // element type  sendx uint // send index  recvx uint // receive index  recvq waitq // list of recv waiters  sendq waitq // list of send waiters  // lock protects all fields in hchan, as well as several  // fields in sudogs blocked on this channel.  //  // Do not change another G\u0026#39;s status while holding this lock  // (in particular, do not ready a G), as this can deadlock  // with stack shrinking.  lock mutex }   可能看源代码不是很好看得懂，这里我个人画了一张图方便大家查看，我在上面标注了不同颜色，并且注释其作用。\n通道像一个传送带或者队列，总是遵循FIFO的规则，保证收发数据的顺序，通道是goroutine间重要通信的方式，是并发安全的。\n   buf  hchan结构体中的buf指向一个循环队列，用来实现循环队列，sendx是循环队列的队尾指针，recvx是循环队列的队头指针，dataqsize是缓存型通道的大小，qcount是记录通道内元素个数。\n在日常开发过程中用的最多就是ch := make(chan int, 10)这样的方式创建一个通道，如果这要声明初始化的话，这个通道就是有缓冲区的，也是图上紫色的buf，buf是在make的时候程序创建的，它有元素大小*元素个数组成一个循环队列，可以看做成一个环形结构，buf则是一个指针指向这个环。\n上图对应的代码那就是ch = make(chan int,6)，buf指向这个环在heap上的地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe.  if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026#34;makechan: bad alignment\u0026#34;) } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers.  // buf points into the same allocation, elemtype is persistent.  // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected.  // TODO(dvyukov,rlh): Rethink when collector can move allocated objects.  var c *hchan switch { case mem == 0: // Queue or element size is zero.  c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization.  c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers.  // Allocate hchan and buf in one call.  c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers.  c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) if debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c }   上面就是对应的代码实现，上来它会检查你一系列参数是否合法，然后在通过mallocgc在内存开辟这块空间，然后返回。\n   sendx and recvx  下面我手动模拟一个ring实现的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  // Queue cycle buffer type CycleQueue struct { data []interface{} // 存放元素的数组，准确来说是切片  frontIndex, rearIndex int // frontIndex 头指针,rearIndex 尾指针  size int // circular 的大小 } // NewQueue Circular Queue func NewQueue(size int) (*CycleQueue, error) { if size \u0026lt;= 0 || size \u0026lt; 10 { return nil, fmt.Errorf(\u0026#34;initialize circular queue size fail,%d not legal,size \u0026gt;= 10\u0026#34;, size) } cq := new(CycleQueue) cq.data = make([]interface{}, size) cq.size = size return cq, nil } // Push add data to queue func (q *CycleQueue) Push(value interface{}) error { if (q.rearIndex+1)%cap(q.data) == q.frontIndex { return errors.New(\u0026#34;circular queue full\u0026#34;) } q.data[q.rearIndex] = value q.rearIndex = (q.rearIndex + 1) % cap(q.data) return nil } // Pop return queue a front element func (q *CycleQueue) Pop() interface{} { if q.rearIndex == q.frontIndex { return nil } v := q.data[q.frontIndex] q.data[q.frontIndex] = nil // 拿除元素 位置就设置为空  q.frontIndex = (q.frontIndex + 1) % cap(q.data) return v }   循环队列一般使用空余单元法来解决队空和队满时候都存在font=rear带来的二义性问题，但这样会浪费一个单元。golang的channel中是通过增加qcount字段记录队列长度来解决二义性，一方面不会浪费一个存储单元，另一方面当使用len函数查看队列长度时候，可以直接返回qcount字段，一举两得。\n当我们需要读取的数据的时候直接从recvx指针上的元素取，而写就从sendx位置写入元素，如图：\n   sendq and recvq  当写入数据的如果缓冲区已经满或者读取的缓冲区已经没有数据的时候，就会发生协程阻塞。\n如果写阻塞的时候会把当前的协程加入到sendq的队列中，直到有一个recvq发起了一个读取的操作，那么写的队列就会被程序唤醒进行工作。\n当缓冲区满了所有的g-w则被加入sendq队列等待g-r有操作就被唤醒g-w，继续工作，这种设计和操作系统的里面thread的5种状态很接近了，可以看出go的设计者在可能参考过操作系统的thread设计。\n当然上面只是我简述整个个过程，实际上go还做了其他细节优化，sendq不为空的时候，并且没有缓冲区，也就是无缓冲区通道，此时会从sendq第一个协程中拿取数据，有兴趣的gopher可以去自己查看源代码，本文也是最近笔者在看到这块源代码的笔记总结。\n","date":"Sep 16","permalink":"http://blog.ibyte.me/post/golang-channel-desgin/","tags":null,"title":"Golang Channel Desgin"},{"categories":null,"contents":"   前 言  很多时候为了更快的开发效率，大多数程序员都是在使用抽象层级更高的技术，包括语言，框架，设计模式等。所以导致很多程序员包括我自己在内对于底层和基础的知识都会有些生疏和，但是正是这些底层的东西构建了我们熟知的解决方案，同时决定了一个技术人员的上限。\n在写C和C++的时候动态分配内存是让程序员自己手动管理，这样做的好处是，需要申请多少内存空间可以很好的掌握怎么分配，但是如果忘记释放内存，则会导致内存泄漏。\nRust又比👆上面俩门语言分配内存方式显得不同，Rust的内存管理主要特色可以看做是编译器帮你在适当的地方插入delete来释放内存，这样一来你不需要显式指定释放，runtime也不需要任何GC，但是要做到这点，编译器需要能分析出在什么地方delete，这就需要你代码按照其规则来写了。\n相比上面几种的内存管理方式的语言，像Java和Golang在语言设计的时候就加入了garbage collection也就runtime中的gc，让程序员不需要自己管理内存，真正解放了程序员的双手，让我们可以专注于编码。\n   函数栈帧  当一个函数在运行时，需要为它在堆栈中创建一个栈帧（stack frame）用来记录运行时产生的相关信息，因此每个函数在执行前都会创建一个栈帧，在它返回时会销毁该栈帧。\n通常用一个叫做栈基址（bp）的寄存器来保存正在运行函数栈帧的开始地址，由于栈指针（sp）始终保存的是栈顶的地址，所以栈指针保存的也就是正在运行函数栈帧的结束地址。\n销毁时先把栈指针（sp）移动到此时栈基址（bp）的位置，此时栈指针和栈基址都指向同样的位置。\n   Go内存逃逸  可以简单得理解成一次函数调用内部申请到的内存，它们会随着函数的返回把内存还给系统。下面来看看一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package main import \u0026#34;fmt\u0026#34; func main() { f := foo(\u0026#34;Ding\u0026#34;) fmt.Println(f) } type bar struct { s string } func foo(s string) bar { f := new(bar) // 这里的new(bar)会不会发生逃逸？？？  defer func() { f = nil }() f.s = s return *f }   我想很多人认为发生了逃逸，但是真的是这样的吗？那就用go build -gcflags=-m escape/struct.go看看会输出什么？？？\n其实没有发生逃逸，而escape/struct.go:7:13: f escapes to heap的逃逸是因为动态类型逃逸，fmt.Println(a …interface{})在编译期间很难确定其参数的具体类型，也能产生逃逸。\n继续看下面这一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package main import \u0026#34;fmt\u0026#34; func main() { f := foo(\u0026#34;Ding\u0026#34;) fmt.Println(f) } type bar struct { s string } func foo(s string) *bar { f := new(bar) // 这里的new(bar)会不会发生逃逸？？？  defer func() { f = nil }() f.s = s return f }   f := new(bar)会发生逃逸吗？\n1 2 3 4 5 6 7 8 9  $: go build -gcflags=-m escape/struct.go # command-line-arguments escape/struct.go:16:8: can inline foo.func1 escape/struct.go:7:13: inlining call to fmt.Println escape/struct.go:14:10: leaking param: s escape/struct.go:15:10: new(bar) escapes to heap ✅ escape/struct.go:16:8: func literal does not escape escape/struct.go:7:13: []interface {}{...} does not escape \u0026lt;autogenerated\u0026gt;:1: .this does not escape   Go可以返回局部变量指针，这其实是一个典型的变量逃逸案例，虽然在函数 foo() 内部 f 为局部变量，其值通过函数返回值返回，f 本身为一指针，其指向的内存地址不会是栈而是堆，这就是典型的逃逸案例。\n那就继续往下看吧，看看这个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  package main func main() { Slice() // ？？？ 会发生逃逸吗？ } func Slice() { s := make([]int, 10000, 10000) for index, _ := range s { s[index] = index } }   估计很多人会回答没有，其实这里发生逃逸，实际上当栈空间不足以存放当前对象时或无法判断当前切片长度时会将对象分配到堆中。\n最后一个例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) func main() { Println(string(*ReverseA(\u0026#34;Ding Ding\u0026#34;))) // ??? } func Println(str string) { io.WriteString(os.Stdout, str+\u0026#34;\\n\u0026#34;) } func ReverseA(str string) *[]rune { result := make([]rune, 0, len(str)) for _, v := range []rune(str) { v := v defer func() { result = append(result, v) }() } return \u0026amp;result }   如果一个变量被取地址，通过函数返回指针值返回，还有闭包，编译器不确定你的切片容量时，是否要扩容的时候，放到堆上，以致产生逃逸。\n于是我优化了一下代码，再看看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package main import ( \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) func main() { result := []rune(\u0026#34;Ding Ding\u0026#34;) ReverseB(result) Println(string(result)) } func ReverseB(runes []rune) { for i, j := 0, len(runes)-1; i \u0026lt; j; i, j = i+1, j-1 { runes[i], runes[j] = runes[j], runes[i] } } func Println(str string) { io.WriteString(os.Stdout, str+\u0026#34;\\n\u0026#34;) }      如何得知变量是怎么分配？   引用 (golang.org) FAQ官方说的：\n 准确地说，你并不需要知道，Golang 中的变量只要被引用就一直会存活，存储在堆上还是栈上由内部实现决定而和具体的语法没有关系。知道变量的存储位置确实和效率编程有关系。如果可能，Golang 编译器会将函数的局部变量分配到函数栈帧（stack frame）上， 然而，如果编译器不能确保变量在函数 return之后不再被引用，编译器就会将变量分配到堆上。而且，如果一个局部变量非常大，那么它也应该被分配到堆上而不是栈上。\n   小 结   逃逸分析的好处是为了减少gc的压力 栈上分配的内存不需要gc处理 同步消除，如果你定义的对象的方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行。  ","date":"Sep 16","permalink":"http://blog.ibyte.me/post/golang-memory-escape-analysis/","tags":null,"title":"Golang Memory Escape Analysis"},{"categories":["syntax"],"contents":"Lorem ipsum dolor sit amet1 consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum consequatur animi.\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum2 consequatur animi.\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum consequatur animi.\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum consequatur animi.\n  Test Footnote\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Test Footnote2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"May 31","permalink":"http://blog.ibyte.me/post-copy/footnote/","tags":null,"title":"Footnote test"},{"categories":["math"],"contents":"The following\n$$ \\int_{a}^{b} x^2 dx $$\nIs an integral\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\nEnable Katex in the config file by setting the katex param to true. This will import the necessary Katex CSS/JS.\nSee the online reference of supported TeX functions.\n1  Inline math: $\\varphi=\\dfrac{1+\\sqrt5}{2}=1.6180339887… $   Inline math: $ \\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887… $\n1 2 3  Block math: $$\\varphi=1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$   Block math:\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"May 22","permalink":"http://blog.ibyte.me/post-copy/test-katex/","tags":null,"title":"Katex support"},{"categories":["math"],"contents":"The following\n$$ \\int_{a}^{b} x^2 dx $$\nIs an integral\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\nEnable MathJax in the config file by setting the mathjax param to true. This will import the necessary MathJax CSS/JS.\n1  Inline math: $\\varphi=\\dfrac{1+\\sqrt5}{2}=1.6180339887… $   Inline math: $ \\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887… $\n1 2 3  Block math: $$\\varphi=1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$   Block math:\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"May 22","permalink":"http://blog.ibyte.me/post-copy/test-mathjax/","tags":null,"title":"MathJax support"},{"categories":null,"contents":"","date":"Nov 26","permalink":"http://blog.ibyte.me/articles/","tags":null,"title":"Articles"},{"categories":["themes","syntax"],"contents":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\n   Headings  The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\n   H1     H2     H3     H4     H5     H6     Paragraph  Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\n   Blockquotes  The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\n   Blockquote without attribution   Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n    Blockquote with attribution   Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\n    Tables  Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23       Inline Markdown within tables     Italics Bold Code     italics bold code       Code Blocks     Code block with backticks  1 2 3 4 5 6 7 8 9 10  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;      Code block indented with four spaces  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;     Code block with Hugo\u0026amp;rsquo;s internal highlight shortcode  1 2 3 4 5 6 7 8 9 10  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;      List Types     Ordered List   First item Second item Third item     Unordered List   List item Another item And another item     Nested list   Fruit  Apple Orange Banana   Dairy  Milk Cheese       Other Elements — abbr, sub, sup, kbd, mark  GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n  The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  ","date":"Mar 11","permalink":"http://blog.ibyte.me/post-copy/markdown-syntax/","tags":["markdown","css","html"],"title":"Markdown Syntax Guide"},{"categories":null,"contents":"   Nya nya nyan meow meow mama  More napping, more napping all the napping is exhausting stretch out on bed you are a captive audience while sitting on the toilet, pet me slap the dog because cats rule bleghbleghvomit my furball really tie the room together always hungry. Humans,humans, humans oh how much they love us felines we are the center of attention they feed, they clean miaow then turn around and show you my bum. Cats secretly make all the worlds muffins slap owner\u0026rsquo;s face at 5am until human fills food dish, milk the cow hunt by meowing loudly at 5am next to human slave food dispenser throwup on your pillow. Get scared by doggo also cucumerro .\n   Cat is meow meow  Sees bird in air, breaks into cage and attacks creature when in doubt, wash spend six hours per day washing, but still have a crusty butthole yet lick sellotape tickle my belly at your own peril i will pester for food when you\u0026rsquo;re in the kitchen even if it\u0026rsquo;s salad find box a little too small and curl up with fur hanging out.\nClaw at curtains stretch and yawn nibble on tuna ignore human bite human hand. Under the bed mice yet funny little cat chirrup noise shaking upright tail when standing next to you but white cat sleeps on a black shirt for eat an easter feather as if it were a bird then burp victoriously.\n   Has closed eyes but still sees you present belly  scratch hand when stroked for is good you understand your place in my world get scared by sudden appearance of cucumber. What the heck just happened, something feels fishy chew master\u0026rsquo;s slippers yet brown cats with pink ears bite the neighbor\u0026rsquo;s bratty kid cereal boxes make for five star accommodation but i like to spend my days sleeping and eating fishes that my human fished for me we live on a luxurious yacht, sailing proudly under the sun, i like to walk on the deck, watching the horizon, dreaming of a good bowl of milk. Lounge in doorway put butt in owner\u0026rsquo;s face, or ptracy destroy house in 5 seconds. Mrow no, you can\u0026rsquo;t close the door, i haven\u0026rsquo;t decided whether or not i wanna go out is good you understand your place in my world.\nBrown cats with pink ears shred all toilet paper and spread around the house being gorgeous with belly side up. Cats go for world domination the best thing in the universe is a cardboard box cats are cute so meow all night having their mate disturbing sleeping humans. Nya nya nyan annoy owner until he gives you food say meow repeatedly until belly rubs, feels good eat the fat cats food but meowing non stop for food. Pet right here, no not there, here, no fool, right here that other cat smells funny you should really give me all the treats because i smell the best and omg you finally got the right spot and i love you right now see brother cat receive pets, attack out of jealousy. Headbutt owner\u0026rsquo;s knee love blinks and purr purr purr purr yawn for stand in front of the computer screen, or mew mew for human is washing you why halp oh the horror flee scratch hiss bite.\n   Cats making all the muffins  Cats making all the muffins asdflkjaertvlkjasntvkjn (sits on keyboard) so the dog smells bad but cough hairball on conveniently placed pants and show belly but loved it, hated it, loved it, hated it catch mouse and gave it as a present. Give me attention or face the wrath of my claws meow all night for love me! and love you, then bite you or mesmerizing birds. Lick human with sandpaper tongue. Murf pratt ungow ungow scratch the box sit in box and to pet a cat, rub its belly, endure blood and agony, quietly weep, keep rubbing belly wake up human for food at 4am or eat owner\u0026rsquo;s food trip owner up in kitchen i want food. Curl up and sleep on the freshly laundered towels paw at your fat belly, steal mom\u0026rsquo;s crouton while she is in the bathroom yet nyan nyan goes the cat, scraaaaape scraaaape goes the walls when the cat murders them with its claws milk the cow suddenly go on wild-eyed crazy rampage toy mouse squeak roll over.\nHunt by meowing loudly at 5am next to human slave food dispenser hate dog reward the chosen human with a slow blink. Cat dog hate mouse eat string barf pillow no baths hate everything miaow then turn around and show you my bum love fish, and kitty scratches couch bad kitty steal the warm chair right after you get up kitty poochy munch on tasty moths. Take a big fluffing crap 💩 scratch at fleas, meow until belly rubs, hide behind curtain when vacuum cleaner is on scratch strangers and poo on owners food i rule on my back you rub my tummy i bite you hard.\nThanks by cats.\n","date":"Mar 09","permalink":"http://blog.ibyte.me/post-copy/example-lazy-load-image/","tags":["markdown","text","image"],"title":"Example Lazy Load Image"},{"categories":null,"contents":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\n Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude  Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\n Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et     Vagus elidunt  \nThe Van de Graaf Canon\n   Mane refeci capiebant unda mulcebat  Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"Mar 09","permalink":"http://blog.ibyte.me/post-copy/placeholder-text/","tags":["markdown","text"],"title":"Placeholder Text"},{"categories":null,"contents":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\n N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3  .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; }  ","date":"Mar 05","permalink":"http://blog.ibyte.me/post-copy/emoji-support/","tags":["emoji"],"title":"Emoji Support"}]